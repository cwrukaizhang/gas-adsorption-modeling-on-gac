{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTLnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MTLnet, self).__init__()\n",
    "\n",
    "        self.sharedlayer = nn.Sequential(\n",
    "            nn.Linear(feature_size, shared_layer_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout()\n",
    "        )\n",
    "        self.tower1 = nn.Sequential(\n",
    "            nn.Linear(shared_layer_size, tower_h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(tower_h1, tower_h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(tower_h2, output_size)\n",
    "        )\n",
    "        self.tower2 = nn.Sequential(\n",
    "            nn.Linear(shared_layer_size, tower_h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(tower_h1, tower_h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(tower_h2, output_size)\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h_shared = self.sharedlayer(x)\n",
    "        out1 = self.tower1(h_shared)\n",
    "        out2 = self.tower2(h_shared)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bartpy\n",
    "from bartpy.sklearnmodel import SklearnModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交替训练 Alternative Trainning\n",
    "# and joint learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared last layers for inversed multi-task learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_full(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(Net_full,self).__init__()\n",
    "        self.partA = nn.Sequential(nn.Linear(input_dim,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,20),nn.ReLU(),nn.Dropout(0.4))\n",
    "        self.partC = nn.Sequential(nn.Linear(20,10),nn.ReLU(),nn.Linear(10,1))\n",
    "    def forward(self,x):\n",
    "        out = self.partA(x)\n",
    "        out = self.partC(out)\n",
    "        return out\n",
    "class Net_half(nn.Module):\n",
    "    def __init__(self,input_dim,shared_mol):\n",
    "        super(Net_half,self).__init__()\n",
    "        self.partA = nn.Sequential(nn.Linear(input_dim,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,20),nn.ReLU(),nn.Dropout(0.4))\n",
    "        self.partB = shared_mol\n",
    "    def forward(self,x):\n",
    "        out = self.partA(x)\n",
    "        out = self.partB(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def group_split(data:pd.DataFrame,index: list):\n",
    "    ls =len(index)\n",
    "    test_index= np.random.choice(index,int(0.2*ls),replace=False)\n",
    "    train_data = data.loc[~data['Index'].isin( test_index)]\n",
    "    test_data = data.loc[data['Index'].isin( test_index)]\n",
    "    return train_data,test_data\n",
    "def pred_dataset(file_names):\n",
    "    source_path = '/Users/kai/Documents/Desktop/CO2_adsorption/new_data'\n",
    "    train_df_full = pd.DataFrame()\n",
    "    test_df_full = pd.DataFrame()\n",
    "    train_df_half = pd.DataFrame()\n",
    "    test_df_half = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-01-10-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",\"Vt\"])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        data_half = temp_data[temp_data[\"Vmic\"].isna()]\n",
    "        data_full = temp_data.dropna(axis=0,how = 'any',subset = [\"Vmic\",\"Vmeso\"])\n",
    "        train_full,test_full = group_split(data_full,list(set(data_full['Index'].values)))\n",
    "        train_half,test_half = group_split(data_half,list(set(data_half['Index'].values)))\n",
    "        \n",
    "        train_df_full = pd.concat([train_df_full,train_full],axis=0)\n",
    "        test_df_full = pd.concat([test_df_full,test_full],axis =0)\n",
    "        train_df_half = pd.concat([train_df_half,train_half],axis=0)\n",
    "        test_df_half = pd.concat([test_df_half,test_half],axis =0)\n",
    "    return train_df_full,test_df_full,train_df_half,test_df_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_full,test_df_full,train_df_half,test_df_half = pred_dataset(['CO2',\"Ethane&Ethylene\",'CFCs','Methane'])#,\"Ethane&Ethylene\",'CFCs']) #'Hydrogen',,'Methane','Ethane&Ethylene','CFCs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21565, 25)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8601, 25)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,idx):   \n",
    "        return self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "def data_pred(data_train:pd.DataFrame,data_test:pd.DataFrame,input_feature:list):\n",
    "    scaler = StandardScaler()\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    train_x = scaler.fit_transform(data_train[input_feature])\n",
    "    test_x = scaler.transform(data_test[input_feature])\n",
    "    train_x = torch.Tensor(train_x).float()\n",
    "    test_x = torch.Tensor(test_x).float()\n",
    "    train_y = torch.Tensor(data_train[output].values.reshape(-1,1)).float()\n",
    "    test_y = torch.Tensor(data_test[output].values.reshape(-1,1)).float()\n",
    "    train_loader = DataLoader(CustomDataset(train_x,train_y),batch_size=500)\n",
    "    test_loader = DataLoader(CustomDataset(test_x,test_y),batch_size= 500)\n",
    "\n",
    "    return train_loader,test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature = ['S','V','L','BET',\"Vt\",'Vmeso','Temp(K)','Pressure']\n",
    "half_feature = ['S','V','L','BET',\"Vt\",'Temp(K)','Pressure']\n",
    "\n",
    "train_loader_full,test_loader_full = data_pred(train_df_full,test_df_full,full_feature)\n",
    "train_loader_half,test_loader_half = data_pred(train_df_half,test_df_half,half_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_mode(model,optimizer,loss_fn, train_loader,test_loader,i):\n",
    "    for train_x,train_y in train_loader:\n",
    "        pred = model(train_x)\n",
    "        loss = loss_fn(pred,train_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if i%10==0:\n",
    "        y_real= torch.Tensor(())\n",
    "        y_pred = torch.Tensor(())\n",
    "        with torch.no_grad():\n",
    "            for val_x,val_y in test_loader:\n",
    "                    y_pred = model(val_x) \n",
    "                    \n",
    "                    y_real=torch.cat((y_real,val_y),0)\n",
    "                    y_pred = torch.cat((y_pred,y_pred),0)\n",
    "            val_loss = loss_fn(y_real,y_pred)\n",
    "    print('Epcoh: {}, Train_loss {:.4f}, Val_loss {:.4f}'.format(i,loss,val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "input_dim_full= len(full_feature)\n",
    "input_dim_half= len(half_feature)\n",
    "loss_fn = nn.MSELoss()\n",
    "model_full  = Net_full(input_dim_full)\n",
    "model_half = Net_half(input_dim_half,shared_mol=model_full.partC)\n",
    "optimizer_full = optim.Adam(model_full.parameters(),lr = 1e-3)\n",
    "optimizer_half = optim.Adam(model_half.parameters(),lr = 1e-3)\n",
    "epochs =1000\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model,data_loader,loss_fn):\n",
    "    y_real= torch.Tensor(())\n",
    "    y_preds = torch.Tensor(())\n",
    "    with torch.no_grad():\n",
    "        for test_x,test_y in data_loader:\n",
    "            y_pred = model(test_x) \n",
    "            y_real=torch.cat((y_real,test_y),0)        \n",
    "            y_preds = torch.cat((y_preds,y_pred),0)            \n",
    "            val_loss = loss_fn(y_real,y_preds)            \n",
    "    return val_loss\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,epochs+1):\n",
    "\n",
    "    if np.random.rand()>0.4:\n",
    "        for train_x,train_y in train_loader_full:\n",
    "            pred = model_full(train_x)\n",
    "            loss = loss_fn(pred,train_y)\n",
    "            optimizer_full.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_full.step()\n",
    "        if i%50==0:\n",
    "            full_loss = model_eval(model_full,test_loader_full,loss_fn)\n",
    "            half_loss = model_eval(model_half,test_loader_half,loss_fn)\n",
    "            \n",
    "            print('Epcoh: {}, Train_loss {:.4f}, Val_loss_full {:.4f},Val_loss_half {:.4f}'.format(i,loss,full_loss,half_loss))\n",
    "    else:\n",
    "        for train_x,train_y in train_loader_half:\n",
    "            pred = model_half(train_x)\n",
    "            loss = loss_fn(pred,train_y)\n",
    "            optimizer_half.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_half.step()\n",
    "\n",
    "        if i%50==0:\n",
    "            half_loss = model_eval(model_half,test_loader_half,loss_fn)\n",
    "            full_loss = model_eval(model_full,test_loader_full,loss_fn)\n",
    "            print('Epcoh: {}, Train_loss {:.4f}, Val_loss_half {:.4f},Val_loss_full {:.4f}'.format(i,loss,half_loss,full_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh: 1000, Train_loss 0.6031, Val_loss 3.1595\n"
     ]
    }
   ],
   "source": [
    "y_real= torch.Tensor(())\n",
    "y_preds = torch.Tensor(())\n",
    "with torch.no_grad():\n",
    "    for test_x,test_y in test_loader_half:\n",
    "        y_pred = model_half(test_x) \n",
    "                        \n",
    "        y_real=torch.cat((y_real,test_y),0)\n",
    "        y_preds = torch.cat((y_preds,y_pred),0)\n",
    "                #print(y_real.shape,y_pred.shape)\n",
    "        val_loss = loss_fn(y_real,y_preds)\n",
    "    print('Epcoh: {}, Train_loss {:.4f}, Val_loss {:.4f}'.format(i,loss,val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh: 1000, Train_loss 0.3639, Val_loss 2.0406\n"
     ]
    }
   ],
   "source": [
    "y_real= torch.Tensor(())\n",
    "y_preds = torch.Tensor(())\n",
    "with torch.no_grad():\n",
    "    for test_x,test_y in test_loader_full:\n",
    "        y_pred = model_full(test_x) \n",
    "                        \n",
    "        y_real=torch.cat((y_real,test_y),0)\n",
    "        y_preds = torch.cat((y_preds,y_pred),0)\n",
    "        val_loss = loss_fn(y_real,y_preds)\n",
    "        \n",
    "    print('Epcoh: {}, Train_loss {:.4f}, Val_loss {:.4f}'.format(i,loss,val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31839933, 0.28382548, 0.72745791, 0.51053495, 0.17380269])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_one(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(Net_one,self).__init__()\n",
    "        self.partA = nn.Sequential(nn.Linear(input_dim,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,20),nn.ReLU(),nn.Dropout(0.2))\n",
    "        self.partC = nn.Sequential(nn.Linear(20,10),nn.ReLU(),nn.Linear(10,1))\n",
    "    def forward(self,x):\n",
    "        out = self.partA(x)\n",
    "        out = self.partC(out)\n",
    "        return out\n",
    "class Net_two(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(Net_two,self).__init__()\n",
    "        self.partA = nn.Sequential(nn.Linear(input_dim,30),nn.ReLU(),\n",
    "        nn.Dropout(0.4),nn.Linear(30,20),nn.ReLU(),nn.Dropout(0.4))\n",
    "        self.partB = nn.Sequential(nn.Linear(20,10),nn.ReLU(),nn.Linear(10,1))\n",
    "    def forward(self,x):\n",
    "        out = self.partA(x)\n",
    "        out = self.partB(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "input_dim_full= len(full_feature)\n",
    "input_dim_half= len(half_feature)\n",
    "loss_fn = nn.MSELoss()\n",
    "model_one  = Net_one(input_dim_full)\n",
    "model_two = Net_two(input_dim_half)\n",
    "optimizer_one = optim.Adam(model_one.parameters(),lr = 1e-3)\n",
    "optimizer_two = optim.Adam(model_two.parameters(),lr = 8e-4)\n",
    "epochs =1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dataset with full features\n",
    "for i in range(1,epochs+1):\n",
    "\n",
    "    \n",
    "    for train_x,train_y in train_loader_full:\n",
    "        pred = model_one(train_x)\n",
    "        loss = loss_fn(pred,train_y)\n",
    "        optimizer_one.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer_one.step()\n",
    "    if i%50==0:\n",
    "        full_loss = model_eval(model_one,test_loader_full,loss_fn)\n",
    "            \n",
    "        print('Epcoh: {}, Train_loss {:.4f}, Val_loss {:.4f}'.format(i,loss,full_loss))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcoh: 50, Train_loss 1.3831, Val_loss 4.0738\n",
      "Epcoh: 100, Train_loss 1.0408, Val_loss 3.4842\n",
      "Epcoh: 150, Train_loss 1.1138, Val_loss 3.0293\n",
      "Epcoh: 200, Train_loss 1.2847, Val_loss 2.8968\n",
      "Epcoh: 250, Train_loss 1.3913, Val_loss 2.7893\n",
      "Epcoh: 300, Train_loss 0.9832, Val_loss 2.5984\n",
      "Epcoh: 350, Train_loss 0.8759, Val_loss 2.3934\n",
      "Epcoh: 400, Train_loss 1.2157, Val_loss 2.3051\n",
      "Epcoh: 450, Train_loss 1.0590, Val_loss 2.1051\n",
      "Epcoh: 500, Train_loss 1.5149, Val_loss 2.2021\n",
      "Epcoh: 550, Train_loss 1.0128, Val_loss 2.1186\n",
      "Epcoh: 600, Train_loss 1.1325, Val_loss 2.0566\n",
      "Epcoh: 650, Train_loss 1.0520, Val_loss 2.0398\n",
      "Epcoh: 700, Train_loss 1.1044, Val_loss 2.0430\n",
      "Epcoh: 750, Train_loss 1.1022, Val_loss 1.8783\n",
      "Epcoh: 800, Train_loss 1.0462, Val_loss 2.0092\n",
      "Epcoh: 850, Train_loss 0.8422, Val_loss 1.8942\n",
      "Epcoh: 900, Train_loss 0.8608, Val_loss 1.9157\n",
      "Epcoh: 950, Train_loss 1.1202, Val_loss 1.8950\n",
      "Epcoh: 1000, Train_loss 1.0000, Val_loss 1.7805\n"
     ]
    }
   ],
   "source": [
    "# using dataset with half features\n",
    "for i in range(1,epochs+1):\n",
    "\n",
    "    \n",
    "    for train_x,train_y in train_loader_half:\n",
    "        pred = model_two(train_x)\n",
    "        loss = loss_fn(pred,train_y)\n",
    "        optimizer_two.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer_two.step()\n",
    "    if i%50==0:\n",
    "        full_loss = model_eval(model_two,test_loader_half,loss_fn)\n",
    "            \n",
    "        print('Epcoh: {}, Train_loss {:.4f}, Val_loss {:.4f}'.format(i,loss,full_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with simple algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,\\\n",
    "    GradientBoostingRegressor,ExtraTreesRegressor, BaggingRegressor,StackingRegressor,\\\n",
    "    VotingRegressor,HistGradientBoostingRegressor\n",
    "model_list = [('RF',RandomForestRegressor(n_estimators=20)),('ADB',AdaBoostRegressor(n_estimators=30)),\n",
    "('GBR',GradientBoostingRegressor(n_estimators=30)),('ETR',ExtraTreesRegressor(n_estimators=30)),\n",
    "('BRR',BaggingRegressor(base_estimator=RandomForestRegressor(n_estimators=5),n_estimators=20))]\n",
    "model_svm = [('LSVR',SVR(kernel='linear')),('PSVR',SVR(kernel='poly')),('RSVR',SVR(kernel='rbf'))]\n",
    "    \n",
    "ensemble_list = [('SR',StackingRegressor(model_list)),('VR',VotingRegressor(model_list)),\n",
    "('HGBT',HistGradientBoostingRegressor(model_list))]\n",
    "  \n",
    "#train_x = scaler.fit_transform(train_df.iloc[:,:-1])\n",
    "#test_x = scaler.transform(test_df.iloc[:,:-1])\n",
    "#input_feature = ['E','V','L','BET',\"Vt\",'Vmic','Temp(K)','Pressure'] #with Vmic\n",
    "input_feature = ['S','V','L','BET',\"Vmeso\",'Vt','Vmic','Temp(K)','Pressure'] # without Vmic\n",
    "#input_feature = ['E','V','L','BET',\"Vmeso\",'Vmic','Temp(K)','Pressure'] # break Vt\n",
    "output = ['Adsorp(mmol/g)']\n",
    "train_x= train_df_full[input_feature]\n",
    "test_x = test_df_full[input_feature]\n",
    "train_y = train_df_full[output]\n",
    "test_y = test_df_full[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature = ['S','V','L','BET',\"Vt\",'Temp(K)','Pressure'] # without Vmic\n",
    "#input_feature = ['E','V','L','BET',\"Vmeso\",'Vmic','Temp(K)','Pressure'] # break Vt\n",
    "output = ['Adsorp(mmol/g)']\n",
    "train_x= train_df_half[input_feature]\n",
    "test_x = test_df_half[input_feature]\n",
    "train_y = train_df_half[output]\n",
    "test_y = test_df_half[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm RF, Train_error 0.04963738328307915, Test_error 0.959339947983029\n",
      "Algorithm ADB, Train_error 3.0812959162456224, Test_error 3.469649624062843\n",
      "Algorithm GBR, Train_error 1.8455888863275807, Test_error 2.1607537428963677\n",
      "Algorithm ETR, Train_error 3.8399706909490366e-30, Test_error 0.8326973443796771\n",
      "Algorithm BRR, Train_error 0.12314842319647636, Test_error 0.895806456801427\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in model_list:\n",
    "\n",
    "    model.fit(train_x,train_y)\n",
    "    test_pre = model.predict(test_x)\n",
    "    train_error = mean_squared_error(train_y,model.predict(train_x))\n",
    "    test_error = mean_squared_error(test_y,test_pre)\n",
    "    print('Algorithm {}, Train_error {}, Test_error {}'.format(model_name,train_error,test_error))\n",
    "    #plt.scatter(test_y,test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression chain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pick_six(data, index_list):\n",
    "    df = pd.DataFrame()\n",
    "    for index in index_list:\n",
    "        temp_data  = data[data['Index']==index]\n",
    "        if len(temp_data)>=6:\n",
    "            new_index = np.random.choice(list(temp_data['Index'].values),6,replace =False)\n",
    "            new_index = sorted(new_index)\n",
    "            df = pd.concat([df,temp_data.loc[temp_data['Index'].isin(new_index)]],axis=0)\n",
    "    return df\n",
    "    \n",
    "def pred_dataset(file_names):\n",
    "    source_path = '/Users/kai/Documents/Desktop/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-01-10-2022.xlsx'),skiprows= 1 )\n",
    "        \n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",\"Vt\",'Vmic','Vmeso'])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.1]\n",
    "        #temp_data = temp_data[temp_data['Pressure']<1]\n",
    "        index = set(temp_data['Index'].values)\n",
    "        test_index= np.random.choice(list(index),int(0.2*len(index)),replace=False)\n",
    "        train_index = [x for x in index if x not in test_index]\n",
    "        #train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        #test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        train_x = pick_six(temp_data, train_index)\n",
    "        test_x = pick_six(temp_data,test_index)\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs',])\n",
    "#,,'CFCs']) #'Hydrogen','CO2','Methane','Ethane&Ethylene','CFCs','Hydrogen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Literature</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>GAC</th>\n",
       "      <th>GAS</th>\n",
       "      <th>E</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>V</th>\n",
       "      <th>L</th>\n",
       "      <th>...</th>\n",
       "      <th>%O</th>\n",
       "      <th>%N</th>\n",
       "      <th>Temp(K)</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Adsorp(mmol/g)</th>\n",
       "      <th>Index</th>\n",
       "      <th>logP</th>\n",
       "      <th>logQ</th>\n",
       "      <th>logD</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CarbonDiox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.103286</td>\n",
       "      <td>0.722063</td>\n",
       "      <td>31</td>\n",
       "      <td>-2.270250</td>\n",
       "      <td>-0.325643</td>\n",
       "      <td>1.944607</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CarbonDiox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.187793</td>\n",
       "      <td>1.111748</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.672413</td>\n",
       "      <td>0.105933</td>\n",
       "      <td>1.778346</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CarbonDiox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>1.455587</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.266948</td>\n",
       "      <td>0.375410</td>\n",
       "      <td>1.642357</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CarbonDiox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.370892</td>\n",
       "      <td>1.799427</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.991844</td>\n",
       "      <td>0.587468</td>\n",
       "      <td>1.579313</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CarbonDiox</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.502347</td>\n",
       "      <td>2.212034</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.688463</td>\n",
       "      <td>0.793913</td>\n",
       "      <td>1.482376</td>\n",
       "      <td>CO2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Literature  Unnamed: 1  GAC         GAS    E     S     A    B       V  \\\n",
       "547        NaN           2  NaN  CarbonDiox  0.0  0.28  0.05  0.1  0.2809   \n",
       "548        NaN           3  NaN  CarbonDiox  0.0  0.28  0.05  0.1  0.2809   \n",
       "549        NaN           4  NaN  CarbonDiox  0.0  0.28  0.05  0.1  0.2809   \n",
       "550        NaN           5  NaN  CarbonDiox  0.0  0.28  0.05  0.1  0.2809   \n",
       "551        NaN           6  NaN  CarbonDiox  0.0  0.28  0.05  0.1  0.2809   \n",
       "\n",
       "         L  ...  %O  %N  Temp(K)  Pressure  Adsorp(mmol/g)  Index      logP  \\\n",
       "547  0.058  ... NaN NaN    298.0  0.103286        0.722063     31 -2.270250   \n",
       "548  0.058  ... NaN NaN    298.0  0.187793        1.111748     31 -1.672413   \n",
       "549  0.058  ... NaN NaN    298.0  0.281690        1.455587     31 -1.266948   \n",
       "550  0.058  ... NaN NaN    298.0  0.370892        1.799427     31 -0.991844   \n",
       "551  0.058  ... NaN NaN    298.0  0.502347        2.212034     31 -0.688463   \n",
       "\n",
       "         logQ      logD  Label  \n",
       "547 -0.325643  1.944607    CO2  \n",
       "548  0.105933  1.778346    CO2  \n",
       "549  0.375410  1.642357    CO2  \n",
       "550  0.587468  1.579313    CO2  \n",
       "551  0.793913  1.482376    CO2  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous  simple model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,\\\n",
    "    GradientBoostingRegressor,ExtraTreesRegressor, BaggingRegressor,StackingRegressor,\\\n",
    "    VotingRegressor,HistGradientBoostingRegressor\n",
    "model_list = [('RF',RandomForestRegressor(n_estimators=20)),('ADB',AdaBoostRegressor(n_estimators=30)),\n",
    "('GBR',GradientBoostingRegressor(n_estimators=30)),('ETR',ExtraTreesRegressor(n_estimators=30)),\n",
    "('BRR',BaggingRegressor(base_estimator=RandomForestRegressor(n_estimators=5),n_estimators=20))]\n",
    "  \n",
    "input_feature = ['S','V','L','BET',\"Vmeso\",'Vt','Vmic','Temp(K)','logP'] # without Vmic\n",
    "output = ['logQ']\n",
    "train_x= train_df[input_feature]\n",
    "test_x = test_df[input_feature]\n",
    "train_y = train_df[output]\n",
    "test_y = test_df[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm RF, Train_error 0.00865836445335093, Test_error 0.08623348376664657\n",
      "Algorithm ADB, Train_error 0.24728317117334753, Test_error 0.22979300723222706\n",
      "Algorithm GBR, Train_error 0.14639884313405788, Test_error 0.13822676171691764\n",
      "Algorithm ETR, Train_error 7.779557638441807e-05, Test_error 0.08339469191538657\n",
      "Algorithm BRR, Train_error 0.020304587657683344, Test_error 0.08033489408699486\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in model_list:\n",
    "\n",
    "    model.fit(train_x,train_y)\n",
    "    test_pre = model.predict(test_x)\n",
    "    train_error = mean_squared_error(train_y,model.predict(train_x))\n",
    "    test_error = mean_squared_error(test_y,test_pre)\n",
    "    print('Algorithm {}, Train_error {}, Test_error {}'.format(model_name,train_error,test_error))\n",
    "    #plt.scatter(test_y,test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression chain models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_six(data, index_list):\n",
    "    df = pd.DataFrame()\n",
    "    for index in index_list:\n",
    "        temp_data  = data[data['Index']==index]\n",
    "        if len(temp_data)>=7:\n",
    "            new_index = np.random.choice(list(range(1,len(temp_data)-1)),5,replace =False)\n",
    "            \n",
    "            temp_index = np.append(new_index,[0,len(temp_data)-1]) # cover the begin and end points\n",
    "            \n",
    "            #new_index = new_index+[len(temp_data)-1] # cover the begin and end points\n",
    "            \n",
    "            new_index = sorted(temp_index)\n",
    "            df = pd.concat([df,temp_data.iloc[new_index,:]],axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def pred_dataset(file_names):\n",
    "    source_path = '/Users/kai/Documents/Desktop/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "   \n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-01-10-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",\"Vt\",'Vmic','Vmeso'])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.1]\n",
    "        temp_data = temp_data[temp_data['Vmic']<2]\n",
    "        #temp_data = temp_data[temp_data['Pressure']<1]\n",
    "        index = set(temp_data['Index'].values)\n",
    "        test_index= np.random.choice(list(index),int(0.2*len(index)),replace=False)\n",
    "        train_index = [x for x in index if x not in test_index]\n",
    "        #train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        #test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        train_x = pick_six(temp_data, train_index)\n",
    "        test_x = pick_six(temp_data,test_index)\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "       \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df= pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs','Hydrogen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16065, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with labels\n",
    "def chain_trans(df):\n",
    "    Labels = set(df['Label'].values)\n",
    "\n",
    "    input_feature = ['S','V','L','BET',\"Vmeso\",'Vt','Vmic','Temp(K)']\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for label in Labels:\n",
    "        temp = df[df['Label']==label]\n",
    "        index_list = list(set(temp['Index'].values))\n",
    "\n",
    "        for index in index_list:\n",
    "            temp_df = temp[temp['Index']==index]\n",
    "            temp_x_l = temp_df[input_feature].iloc[0,:].values\n",
    "            temp_x_r = temp_df['logP'].values\n",
    "            temp_y = temp_df[temp_df['Index']==index]['logQ'].values\n",
    "            temp_x = temp_x_l.tolist()+temp_x_r.tolist()\n",
    "            data_x.append(temp_x)\n",
    "            data_y.append(temp_y.squeeze().tolist())\n",
    "    return data_x,data_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_ch,train_y_ch = chain_trans(train_df)\n",
    "test_x_ch,test_y_ch = chain_trans(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,\\\n",
    "    GradientBoostingRegressor,ExtraTreesRegressor, BaggingRegressor,StackingRegressor,\\\n",
    "    VotingRegressor,HistGradientBoostingRegressor\n",
    "model_list = [('RF',RandomForestRegressor(n_estimators=20)),('ADB',AdaBoostRegressor(n_estimators=30)),\n",
    "('GBR',GradientBoostingRegressor(n_estimators=30)),('ETR',ExtraTreesRegressor(n_estimators=30)),\n",
    "('BRR',BaggingRegressor(base_estimator=RandomForestRegressor(n_estimators=5),n_estimators=20))]\n",
    "  \n",
    "input_feature = ['S','V','L','BET',\"Vmeso\",'Vt','Vmic','Temp(K)','logP'] # without Vmic\n",
    "output = ['logQ']\n",
    "train_x= train_df[input_feature]\n",
    "test_x = test_df[input_feature]\n",
    "train_y = train_df[output]\n",
    "test_y = test_df[output]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm RF, Train_error 0.009818809179768151, Test_error 0.09217768244209822\n",
      "Algorithm ADB, Train_error 0.31923368937008334, Test_error 0.33582729690144936\n",
      "Algorithm GBR, Train_error 0.21212323643411535, Test_error 0.21358801730153412\n",
      "Algorithm ETR, Train_error 6.0491903210810845e-05, Test_error 0.08799835553724875\n",
      "Algorithm BRR, Train_error 0.023547283860087722, Test_error 0.0879656475324935\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in model_list:\n",
    "\n",
    "    model.fit(train_x,train_y)\n",
    "    test_pre = model.predict(test_x)\n",
    "    train_error = mean_squared_error(train_y,model.predict(train_x))\n",
    "    test_error = mean_squared_error(test_y,test_pre)\n",
    "    print('Algorithm {}, Train_error {}, Test_error {}'.format(model_name,train_error,test_error))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16065, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm RF, Train_error 0.0346483260999338, Test_error 0.11747459149800388, Test_r2 0.8945796179012067\n",
      "Algorithm ADB, Train_error 0.29258130379573527, Test_error 0.32258055150183323, Test_r2 0.7105198276212725\n",
      "Algorithm GBR, Train_error 0.1384540540401468, Test_error 0.16551874220842816, Test_r2 0.8514653353919458\n",
      "Algorithm ETR, Train_error 2.518429859931069e-23, Test_error 0.10305438531821852, Test_r2 0.9075201493474656\n",
      "Algorithm BRR, Train_error 0.05340126485236442, Test_error 0.09402956046745255, Test_r2 0.9156189260447108\n",
      "Algorithm LGBM, Train_error 0.027562126401032734, Test_error 0.10544715194011646, Test_r2 0.905372907392102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "model_list = [('RF',RandomForestRegressor(n_estimators=50)),('ADB',AdaBoostRegressor(n_estimators=150)),\n",
    "('GBR',GradientBoostingRegressor(n_estimators=50)),('ETR',ExtraTreesRegressor(n_estimators=50)),\n",
    "('BRR',BaggingRegressor(base_estimator=LGBMRegressor(objective = 'regression',num_leaves = 20,learning_rate =0.1)))\n",
    ",('LGBM',LGBMRegressor(objective = 'regression',num_leaves = 150,learning_rate =0.1))]\n",
    "scaler = MinMaxScaler()\n",
    "train_x_ch = scaler.fit_transform(train_x_ch)\n",
    "test_x_ch = scaler.transform(test_x_ch)\n",
    "for name,model in model_list:\n",
    "    chain = RegressorChain(base_estimator=model, order=[0,1,2,3,4,5,6]).fit(train_x_ch, train_y_ch)\n",
    "    test_pred = chain.predict(test_x_ch)\n",
    "    train_pred = chain.predict(train_x_ch)\n",
    "    train_error = mean_squared_error(np.array(train_y_ch).reshape(-1,1),np.array(train_pred).reshape(-1,1))\n",
    "    test_error = mean_squared_error(np.array(test_y_ch).reshape(-1,1),np.array(test_pred).reshape(-1,1))\n",
    "    test_r2 = r2_score(np.array(test_y_ch).reshape(-1,1),np.array(test_pred).reshape(-1,1))\n",
    "    print('Algorithm {}, Train_error {}, Test_error {}, Test_r2 {}'.format(name,train_error,test_error,test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm RF, Train_error 0.013965660541622045, Test_error 0.09470580886987506, Test_r2 0.9150120683057904\n",
      "Algorithm ADB, Train_error 0.2678611451250686, Test_error 0.29202102273027813, Test_r2 0.7379436063190783\n",
      "Algorithm GBR, Train_error 0.11626489418253619, Test_error 0.13253517108580828, Test_r2 0.8810644225340228\n",
      "Algorithm ETR, Train_error 4.3888398762114285e-32, Test_error 0.09092177126640633, Test_r2 0.9184078212507212\n",
      "Algorithm LGBM, Train_error 0.004353859177792087, Test_error 0.08526946985762889, Test_r2 0.9234801332005013\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "model_list = [('RF',RandomForestRegressor(n_estimators=50)),('ADB',AdaBoostRegressor(n_estimators=50)),\n",
    "('GBR',GradientBoostingRegressor(n_estimators=50)),('ETR',ExtraTreesRegressor(n_estimators=10)),\n",
    "('LGBM',LGBMRegressor(objective = 'regression',num_leaves = 50,learning_rate =0.2))]\n",
    "\n",
    "\n",
    "for name,model in model_list:\n",
    "    chain = MultiOutputRegressor(estimator=model).fit(train_x_ch, train_y_ch)\n",
    "    test_pred = chain.predict(test_x_ch)\n",
    "    train_pred = chain.predict(train_x_ch)\n",
    "    train_error = mean_squared_error(np.array(train_y_ch).reshape(-1,1),np.array(train_pred).reshape(-1,1))\n",
    "    test_error = mean_squared_error(np.array(test_y_ch).reshape(-1,1),np.array(test_pred).reshape(-1,1))\n",
    "    test_r2 = r2_score(np.array(test_y_ch).reshape(-1,1),np.array(test_pred).reshape(-1,1))\n",
    "    print('Algorithm {}, Train_error {}, Test_error {}, Test_r2 {}'.format(name,train_error,test_error,test_r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26df051d01d2616f6647e27bd4efd6a94574ac1fcd9ed1884653373dfca90d07"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
