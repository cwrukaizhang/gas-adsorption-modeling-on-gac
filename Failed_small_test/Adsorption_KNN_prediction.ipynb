{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pred_dataset(file_names):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    data_df = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-02-01-2022.xlsx'),skiprows= 1 )\n",
    "        \n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",'Vt'])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        #temp_data = temp_data[temp_data['Vmic']<2]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        #print(len(index))\n",
    "        #test_index= np.random.choice(index,int(0.2*len(index)),replace=False)\n",
    "        #train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        #test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        \n",
    "        #train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        data_df = pd.concat([data_df,temp_data],axis =0)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pred_dataset(['CO2']) #,'Methane','Ethane&Ethylene','CFCs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "  \n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "\n",
    "# define different models#,\n",
    "models = [\n",
    "    #('SVR',SVR(max_iter=100000)),\n",
    "    #('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "    # ('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "    #(\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('BG',BaggingRegressor(random_state=42,n_jobs=-1)),\n",
    "    ('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)),\n",
    "    ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    ('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    #('XGBR',XGBRegressor(eta=0.1, subsample=0.7, colsample_bytree=0.8,random_state =42))\n",
    "    #('BGETR',BaggingRegressor(ExtraTreesRegressor(n_estimators = 180,random_state=42,n_jobs=6),random_state=42,n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { \n",
    "    'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "    'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]},\\\n",
    "    'BGETR':{'n_estimators':[10]},\\\n",
    "    'XGBR':{'n_estimators':n_estimators, 'max_depth':[2,4,6,8,10],}\n",
    "      \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature =  ['S','V','L','BET','Vt','Temp(K)','Pressure']\n",
    "output = ['Adsorp(mmol/g)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.35494891 0.08534778 0.20620754\n",
      " 1.73315781]\n",
      "[0.         0.         0.         0.33018374 0.10890361 0.23978394\n",
      " 1.80909177]\n",
      "[0.         0.         0.         0.26234863 0.07037808 0.19865288\n",
      " 1.65956452]\n",
      "[0.         0.         0.         0.30411658 0.10685978 0.20950279\n",
      " 1.69538987]\n",
      "[0.         0.         0.         0.28179072 0.11590965 0.23098287\n",
      " 1.72160102]\n",
      "[0.         0.         0.         0.38461082 0.0868433  0.20226855\n",
      " 1.72930421]\n",
      "[0.         0.         0.         0.33090731 0.10408106 0.21189315\n",
      " 1.7172012 ]\n",
      "[0.         0.         0.         0.37570282 0.09078991 0.22710308\n",
      " 1.74897784]\n",
      "[0.         0.         0.         0.29353193 0.0953408  0.20288947\n",
      " 1.71844607]\n",
      "[0.         0.         0.         0.27740702 0.06180991 0.25316961\n",
      " 1.74067286]\n",
      "[0.         0.         0.         0.29037316 0.09698608 0.23938326\n",
      " 1.77563912]\n",
      "[0.         0.         0.         0.31257966 0.10708858 0.20872462\n",
      " 1.75361868]\n",
      "[0.         0.         0.         0.27815204 0.12454342 0.25009083\n",
      " 1.7980648 ]\n",
      "[0.         0.         0.         0.29956445 0.09981459 0.20846106\n",
      " 1.76247204]\n",
      "[0.         0.         0.         0.32548794 0.09976173 0.20465171\n",
      " 1.76778918]\n",
      "[0.         0.         0.         0.32020222 0.10144309 0.18819533\n",
      " 1.75736364]\n",
      "[0.         0.         0.         0.28669513 0.07642917 0.22166064\n",
      " 1.72827493]\n",
      "[0.         0.         0.         0.35033926 0.10439903 0.20684244\n",
      " 1.725838  ]\n",
      "[0.         0.         0.         0.25149101 0.12156697 0.21149798\n",
      " 1.72561987]\n",
      "[0.         0.         0.         0.29062862 0.07029808 0.22726246\n",
      " 1.69299941]\n",
      "[0.         0.         0.         0.2913731  0.09913768 0.18688487\n",
      " 1.68544975]\n",
      "[0.         0.         0.         0.34430435 0.0959884  0.1994668\n",
      " 1.7102    ]\n",
      "[0.         0.         0.         0.33103051 0.09542899 0.19502515\n",
      " 1.69966367]\n",
      "[0.         0.         0.         0.29848316 0.10765304 0.20294716\n",
      " 1.70098342]\n",
      "[0.         0.         0.         0.3572694  0.09081772 0.21799001\n",
      " 1.71516298]\n",
      "[0.         0.         0.         0.40267122 0.08517285 0.22146937\n",
      " 1.67252237]\n",
      "[0.         0.         0.         0.32570943 0.08406728 0.19983341\n",
      " 1.73029853]\n",
      "[0.         0.         0.         0.31338901 0.08263741 0.19475459\n",
      " 1.69765731]\n",
      "[0.         0.         0.         0.26672039 0.09216954 0.22427218\n",
      " 1.6799889 ]\n",
      "[0.         0.         0.         0.33711291 0.09826575 0.19084412\n",
      " 1.75830573]\n",
      "[0.         0.         0.         0.30031858 0.06785933 0.2302297\n",
      " 1.69337333]\n",
      "[0.         0.         0.         0.34987499 0.10243784 0.23825564\n",
      " 1.8359901 ]\n",
      "[0.         0.         0.         0.29078849 0.08787332 0.20151288\n",
      " 1.69892065]\n",
      "[0.         0.         0.         0.29580878 0.1108542  0.22170967\n",
      " 1.76759141]\n",
      "[0.         0.         0.         0.29227334 0.10388046 0.20317844\n",
      " 1.73900797]\n",
      "[0.         0.         0.         0.27468454 0.11001507 0.21620042\n",
      " 1.74642131]\n",
      "[0.         0.         0.         0.28253766 0.06776347 0.19483609\n",
      " 1.64433233]\n",
      "[0.         0.         0.         0.28001914 0.09777117 0.19274044\n",
      " 1.68554801]\n",
      "[0.         0.         0.         0.35275413 0.08399988 0.2184254\n",
      " 1.73792979]\n",
      "[0.         0.         0.         0.37618781 0.09435162 0.19554398\n",
      " 1.69848499]\n",
      "[0.         0.         0.         0.34166378 0.08281734 0.21352196\n",
      " 1.7404284 ]\n",
      "[0.         0.         0.         0.32716094 0.08735886 0.20178951\n",
      " 1.6817992 ]\n",
      "[0.         0.         0.         0.34013509 0.10796757 0.18761669\n",
      " 1.72849916]\n",
      "[0.         0.         0.         0.27732935 0.07888009 0.21500245\n",
      " 1.69893374]\n",
      "[0.         0.         0.         0.34096079 0.07924406 0.21185463\n",
      " 1.74607057]\n",
      "[0.         0.         0.         0.26084173 0.09365394 0.21641847\n",
      " 1.72432231]\n",
      "[0.         0.         0.         0.40823672 0.07042106 0.2191319\n",
      " 1.76414621]\n",
      "[0.         0.         0.         0.28962614 0.0856831  0.2074652\n",
      " 1.67333254]\n",
      "[0.         0.         0.         0.27108915 0.07243342 0.22368239\n",
      " 1.65298816]\n",
      "[0.         0.         0.         0.3096678  0.11178691 0.2131339\n",
      " 1.74519044]\n",
      "[0.         0.         0.         0.36117143 0.10404158 0.21079085\n",
      " 1.74245201]\n",
      "[0.         0.         0.         0.37611441 0.08842817 0.19830826\n",
      " 1.73301821]\n",
      "[0.         0.         0.         0.33649466 0.08517348 0.20423983\n",
      " 1.6813604 ]\n",
      "[0.         0.         0.         0.32277355 0.1021323  0.22714864\n",
      " 1.78004073]\n",
      "[0.         0.         0.         0.30361018 0.07064262 0.18944607\n",
      " 1.67028004]\n",
      "[0.         0.         0.         0.35314984 0.08071334 0.17281315\n",
      " 1.69783547]\n",
      "[0.         0.         0.         0.35829555 0.09118167 0.2082033\n",
      " 1.66372948]\n",
      "[0.         0.         0.         0.32935308 0.09589974 0.19785315\n",
      " 1.67691431]\n",
      "[0.         0.         0.         0.32882136 0.08625196 0.23318987\n",
      " 1.72173396]\n",
      "[0.         0.         0.         0.32251037 0.09121976 0.20744283\n",
      " 1.72853917]\n",
      "[0.         0.         0.         0.29079381 0.09252029 0.21373955\n",
      " 1.71490402]\n",
      "[0.         0.         0.         0.3101399  0.1043302  0.230033\n",
      " 1.75210366]\n",
      "[0.         0.         0.         0.30341209 0.06844166 0.21790856\n",
      " 1.67722448]\n",
      "[0.         0.         0.         0.3936425  0.10158376 0.18850762\n",
      " 1.71928357]\n",
      "[0.         0.         0.         0.35767113 0.08983139 0.20662916\n",
      " 1.74184448]\n",
      "[0.         0.         0.         0.29059915 0.1202447  0.21396401\n",
      " 1.73845227]\n",
      "[0.         0.         0.         0.3540287  0.09384573 0.18798456\n",
      " 1.68722161]\n",
      "[0.         0.         0.         0.28567868 0.07005275 0.22653358\n",
      " 1.6835304 ]\n",
      "[0.         0.         0.         0.30191496 0.10273525 0.21268561\n",
      " 1.72964166]\n",
      "[0.         0.         0.         0.27813632 0.10379943 0.18968326\n",
      " 1.68468466]\n",
      "[0.         0.         0.         0.33088146 0.09488162 0.19973453\n",
      " 1.70439476]\n",
      "[0.         0.         0.         0.2911648  0.10726552 0.21119294\n",
      " 1.75074413]\n",
      "[0.         0.         0.         0.32609084 0.09202887 0.20357927\n",
      " 1.74685995]\n",
      "[0.         0.         0.         0.32243033 0.09090525 0.20713007\n",
      " 1.68926046]\n",
      "[0.         0.         0.         0.32126276 0.09435673 0.23349482\n",
      " 1.77575324]\n",
      "[0.         0.         0.         0.29537543 0.09623203 0.20236168\n",
      " 1.72794492]\n",
      "[0.         0.         0.         0.25411053 0.11228523 0.20568014\n",
      " 1.69299753]\n",
      "[0.         0.         0.         0.31369598 0.10109039 0.1924367\n",
      " 1.74856148]\n",
      "[0.         0.         0.         0.35537149 0.08675881 0.1932641\n",
      " 1.71781205]\n",
      "[0.         0.         0.         0.41160226 0.08073606 0.19644773\n",
      " 1.6946588 ]\n",
      "[0.         0.         0.         0.34322042 0.09474132 0.22159597\n",
      " 1.78455381]\n",
      "[0.         0.         0.         0.27081283 0.10846049 0.20620828\n",
      " 1.75824543]\n",
      "[0.         0.         0.         0.32207804 0.08551093 0.21653638\n",
      " 1.71745696]\n",
      "[0.         0.         0.         0.30008087 0.08517516 0.20186654\n",
      " 1.7228107 ]\n",
      "[0.         0.         0.         0.33813636 0.0959439  0.20239309\n",
      " 1.75342549]\n",
      "[0.         0.         0.         0.38012781 0.09086599 0.21215473\n",
      " 1.775235  ]\n",
      "[0.         0.         0.         0.34677019 0.08587482 0.19538832\n",
      " 1.7079254 ]\n",
      "[0.         0.         0.         0.28471688 0.07218352 0.22020973\n",
      " 1.69778825]\n",
      "[0.         0.         0.         0.36477388 0.08103415 0.20684625\n",
      " 1.69402579]\n",
      "[0.         0.         0.         0.35413736 0.08491654 0.19578435\n",
      " 1.71597867]\n",
      "[0.         0.         0.         0.31956975 0.0882972  0.19294869\n",
      " 1.62995568]\n",
      "[0.         0.         0.         0.27151682 0.07751194 0.20083825\n",
      " 1.65175852]\n",
      "[0.         0.         0.         0.34709645 0.08395837 0.2027943\n",
      " 1.68350833]\n",
      "[0.         0.         0.         0.26803001 0.09676299 0.17922848\n",
      " 1.70230026]\n",
      "[0.         0.         0.         0.27566849 0.07604149 0.21963575\n",
      " 1.67706925]\n",
      "[0.         0.         0.         0.31394959 0.0689735  0.2232425\n",
      " 1.73825499]\n",
      "[0.         0.         0.         0.33903308 0.08055542 0.21775519\n",
      " 1.66618168]\n",
      "[0.         0.         0.         0.32223157 0.10371285 0.21094954\n",
      " 1.74889048]\n",
      "[0.         0.         0.         0.35189923 0.09471664 0.22368373\n",
      " 1.79368375]\n",
      "[0.         0.         0.         0.32529173 0.10349469 0.26223637\n",
      " 1.76630715]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "features_importances = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    mse_cv = 10\n",
    "    forest_importance = []\n",
    "\n",
    "    indexes = list(set(data['Index'].values))\n",
    "    #selected = np.random.choice(indexes,len(indexes)//5,replace = False)\n",
    "    selected = np.random.choice(indexes,int(len(indexes)*0.6),replace = False) # only for CFCs\n",
    "    random_data = data.loc[data['Index'].isin(selected)]\n",
    "    train_df_com = random_data\n",
    "    train_x = train_df_com[input_feature]\n",
    "    train_y = train_df_com[output].values            \n",
    "    groups = train_df_com['Index'].values\n",
    "    train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "\n",
    "    for model_name, model in models:          \n",
    "        result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "        model_refit = model.set_params(**best_param)\n",
    "        model_refit.fit(train_x,train_y.squeeze())\n",
    "        results = permutation_importance(model_refit,train_x,train_y, n_repeats=10, random_state=42, n_jobs=2)\n",
    "        feature_importances = pd.Series(results.importances_mean)\n",
    "        if result[0]<mse_cv:\n",
    "            mse_cv = result[0]\n",
    "            forest_importance = feature_importances.values\n",
    "    print(forest_importance)\n",
    "    features_importances.append(forest_importance)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.31950523, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.09215328,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20999685]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = np.diag(np.mean(features_importances,axis=0)[0:-1])\n",
    "weight_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the first line of each isotherms\n",
    "\n",
    "first_row = pd.DataFrame()\n",
    "total_index = set(data[\"Index\"].values)\n",
    "for index in total_index:\n",
    "    temp_pd = data[data[\"Index\"]==index]\n",
    "    first_row  = pd.concat([first_row,temp_pd.iloc[0:1,:]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "input_feature = first_row[['S','V','L','BET','Vt','Temp(K)']]\n",
    "input_feature_scale = StandardScaler().fit_transform(input_feature)\n",
    "input_feature_weighted = np.dot(input_feature_scale,weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#kmeans = KMeans(n_clusters=10, random_state=0).fit(input_feature_weighted)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(input_feature_weighted) # only for cfcs\n",
    "group = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = group.tolist()\n",
    "cgroup_index = []\n",
    "total_index = list(total_index)\n",
    "for i in range(len(total_index)):\n",
    "    ls = len(data[data[\"Index\"]==total_index[i]])\n",
    "    temp = [groups[i] for j in range(ls)]\n",
    "    cgroup_index= cgroup_index+temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cgroup'] = cgroup_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_double(data_df):\n",
    "    first_group = list(set(data_df['cgroup'].values))\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for ele in first_group:\n",
    "        temp_data = data[data['cgroup']==ele]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        \n",
    "        test_index= np.random.choice(index,int(0.2*len(index)),replace=False)\n",
    "        train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis=0)\n",
    "    return train_df,test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = split_double(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "  \n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "\n",
    "# define different models#('SVR',SVR(max_iter=10000)),\n",
    "models = [\n",
    "    #('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "     #('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "    #(\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('BG',BaggingRegressor(random_state=42,n_jobs=-1)),\n",
    "    #('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    ('RF',RandomForestRegressor(n_jobs=-1,random_state=42)),\n",
    "   ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    ('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    \n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { #'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "    'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],\n",
    "    'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]}\n",
    "    \n",
    "    }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CVs(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 3)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9077878144761683, 1.650067242438382]\n",
      "Algorithm RF_total, Test_r2 0.9038864525085525, Test_error 1.840939980372061\n",
      "[0.9162729084050772, 1.6296901929732142]\n",
      "Algorithm LGBM_total, Test_r2 0.9444434587374289, Test_error 1.0197588930955372\n",
      "[0.9181454854313141, 1.621798344501478]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9249593418059658, Test_error 1.3649713922675208\n",
      "[0.9118772528907672, 1.6163044423903665]\n",
      "Algorithm RF_total, Test_r2 0.9441246177307865, Test_error 0.9372094190428824\n",
      "[0.9398513966745773, 1.1285209294683456]\n",
      "Algorithm LGBM_total, Test_r2 0.9566550799943051, Test_error 0.734709925900244\n",
      "[0.9445085904325947, 1.0582600926674575]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9693836261326565, Test_error 0.5483708605276558\n",
      "[0.8954611046857197, 1.904084852490956]\n",
      "Algorithm RF_total, Test_r2 0.9380005549806172, Test_error 1.3097959331973312\n",
      "[0.9183684599965902, 1.4922941026482475]\n",
      "Algorithm LGBM_total, Test_r2 0.9554116365354444, Test_error 0.8595976436225283\n",
      "[0.9153578138847145, 1.5426102279147926]\n",
      "Algorithm BGLGBM_total, Test_r2 0.954287485594164, Test_error 0.8970440533329818\n",
      "[0.8862836454497532, 2.057796282553674]\n",
      "Algorithm RF_total, Test_r2 0.9656800297935906, Test_error 0.6203018253435714\n",
      "[0.8922899792957963, 1.8799822500579673]\n",
      "Algorithm LGBM_total, Test_r2 0.9737608066958247, Test_error 0.48761155536615575\n",
      "[0.8930594007268405, 1.8564860982378295]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9764327912604327, Test_error 0.42636197948597465\n",
      "[0.873859061142077, 2.270262707034041]\n",
      "Algorithm RF_total, Test_r2 0.9333408034516256, Test_error 0.7211480125794905\n",
      "[0.911997625323277, 1.5400093682645093]\n",
      "Algorithm LGBM_total, Test_r2 0.9481850036022612, Test_error 0.5695802887877756\n",
      "[0.912503924877497, 1.5571957902672569]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9600426580778353, Test_error 0.46579150320807133\n",
      "[0.9083000585552509, 1.861282704643658]\n",
      "Algorithm RF_total, Test_r2 0.8522930487072463, Test_error 1.787594830228803\n",
      "[0.9377687619372262, 1.291592856529756]\n",
      "Algorithm LGBM_total, Test_r2 0.9225995263226155, Test_error 1.01276404125851\n",
      "[0.9429545228509668, 1.1906533237776131]\n",
      "Algorithm BGLGBM_total, Test_r2 0.933609076953679, Test_error 0.8349890205132401\n",
      "[0.8804893366401408, 2.3385152036695773]\n",
      "Algorithm RF_total, Test_r2 0.9247023853246598, Test_error 0.9817447313018872\n",
      "[0.8654648077204726, 2.5907528994972893]\n",
      "Algorithm LGBM_total, Test_r2 0.9564901295548658, Test_error 0.6054706325500857\n",
      "[0.8862370011634355, 2.207883161227621]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9597542460761931, Test_error 0.538791127001188\n",
      "[0.906213918581428, 1.7257928601435049]\n",
      "Algorithm RF_total, Test_r2 0.9527112724485667, Test_error 0.9985198088265863\n",
      "[0.9263666093708095, 1.4211841743540379]\n",
      "Algorithm LGBM_total, Test_r2 0.9690435794479718, Test_error 0.6797229890642423\n",
      "[0.9281054480479911, 1.3699781726982632]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9738968352523665, Test_error 0.5853335972035277\n",
      "[0.8974944501993875, 1.7885385309510913]\n",
      "Algorithm RF_total, Test_r2 0.9416383188723169, Test_error 1.1861920512272943\n",
      "[0.9275646318175145, 1.4587142498143366]\n",
      "Algorithm LGBM_total, Test_r2 0.9680614142358451, Test_error 0.6117495691515629\n",
      "[0.93410832015232, 1.2552145526510743]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9636093795116873, Test_error 0.7137963042242806\n",
      "[0.893885825995277, 1.8574620388396894]\n",
      "Algorithm RF_total, Test_r2 0.8788819567517744, Test_error 2.738846123171512\n",
      "[0.8788687027414142, 2.0525736059868547]\n",
      "Algorithm LGBM_total, Test_r2 0.9391553410399798, Test_error 1.249941697685285\n",
      "[0.8982072389012684, 1.7451194145193414]\n",
      "Algorithm BGLGBM_total, Test_r2 0.9031350778837401, Test_error 2.0724625212593213\n"
     ]
    }
   ],
   "source": [
    "input_feature =  ['S','V','L','BET','Vt','Temp(K)','Pressure']\n",
    "output = ['Adsorp(mmol/g)']\n",
    "result_total = []\n",
    "for j in range(10):\n",
    "    train_df,test_df = split_double(data)\n",
    "    train_df_com = train_df\n",
    "    test_df_com = test_df\n",
    "    train_x = train_df_com[input_feature]\n",
    "    test_x = test_df_com[input_feature]\n",
    "    train_y = train_df_com[output].values\n",
    "    test_y = test_df_com[output].values\n",
    "    groups = train_df_com['Index'].values\n",
    "    train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "                \n",
    "    for model_name, model in models:\n",
    "\n",
    "                    \n",
    "        result, best_param = model_CVs(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "        print(result)\n",
    "        model_refit = model.set_params(**best_param)\n",
    "        model_refit.fit(train_x,train_y.squeeze())\n",
    "        test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "        result_total.append([model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,best_param])\n",
    "        print('Algorithm {}, Test_r2 {}, Test_error {}'.format(model_name+'_total',test_r2_total,test_mse_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_total).to_csv('KKN__CFCs_total.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
