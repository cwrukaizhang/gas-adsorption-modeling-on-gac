{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pred_dataset(file_names):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    dataset = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-01-10-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",'Vt','Vmic','Vmeso'])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        dataset = pd.concat([dataset,temp_data],axis=0)  \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def pred_dataset(file_names):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-01-10-2022.xlsx'),skiprows= 1 )\n",
    "        \n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = [\"BET\",'Vt',])\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        #temp_data = temp_data[temp_data['Vmic']<2]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        print(len(index))\n",
    "        test_index= np.random.choice(index,int(0.2*len(index)),replace=False)\n",
    "        train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        \n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26956, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n",
      "832\n",
      "394\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "    \n",
    "    \n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "def LOO_CV(model,train_x,train_y,groups,label = '0'):\n",
    "    \n",
    "    out_cv = LeavePGroupsOut(n_groups=1)\n",
    "    train_y_real = np.array([])\n",
    "    train_y_pred = np.array([])\n",
    "    train_y_label = np.array([])\n",
    "\n",
    "    for train_index, test_index in out_cv.split(train_x, train_y, groups):\n",
    "\n",
    "    \n",
    "        X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "        y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "        if len(label)>1:\n",
    "            label_test = label[test_index]\n",
    "            train_y_label = np.append(train_y_label,label_test)\n",
    "\n",
    "        model.fit(X_train,y_train.squeeze())\n",
    "        temp_pred = model.predict(X_test)\n",
    "        train_y_real = np.append(train_y_real,y_test)\n",
    "        train_y_pred = np.append(train_y_pred,temp_pred)\n",
    "        \n",
    "    \n",
    "    if len(label)>1:\n",
    "        return train_y_real,train_y_pred,train_y_label\n",
    "    else:\n",
    "        return train_y_real,train_y_pred\n",
    "\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list):\n",
    "    gas_list = ['total','CO2','CFCs','Methane','E&E']\n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "        if gas =='total':\n",
    "\n",
    "            train_df_com = train_df\n",
    "            train_x = train_df_com[input_feature].values\n",
    "            train_y = train_df_com[output].values\n",
    "            groups = train_df_com['Index'].values\n",
    "            labels = train_df_com[\"Label\"].values\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                y_real,y_pred,label = LOO_CV(model_refit,train_x,train_y.squeeze(),groups,labels) \n",
    "                test_r2_total = r2_score(y_real,y_pred)\n",
    "                test_mse_total = mean_squared_error(y_real,y_pred)\n",
    "                new_df =pd.DataFrame()\n",
    "                new_df['Y_real'] = y_real\n",
    "                new_df['Y_pred'] = y_pred\n",
    "                new_df['Label']  = label\n",
    "                #new_df = pd.DataFrame(np.array([,y_pred,label]),columns = ['Y_real','Y_pred','Label'])\n",
    "                for gas in gas_list[1:]:\n",
    "                    test_df_com = new_df[new_df['Label']==gas]\n",
    "                    test_xs = test_df_com['Y_real'].values\n",
    "                    test_ys = test_df_com['Y_pred'].values\n",
    "                    test_r2,test_mse = r2_score(test_xs,test_ys),mean_squared_error(test_xs,test_ys)\n",
    "                    result_total.append([gas,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature].values\n",
    "            train_y = train_df_com[output].values\n",
    "            groups = train_df_com['Index'].values\n",
    "    \n",
    "            for model_name, model in model_list:\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                test_real,test_pred = LOO_CV(model_refit,train_x,train_y.squeeze(),groups) \n",
    "                test_r2,test_mse = r2_score(test_real,test_pred),mean_squared_error(test_real,test_pred)\n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "  \n",
    "n_estimators = [50,100,150,200,250,300]\n",
    "\n",
    "# define different models#('SVR',SVR(max_iter=10000)),\n",
    "models = [#('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "     #('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "     # (\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "      #('BG',BaggingRegressor(random_state=42,n_jobs=-1)), \n",
    "       #('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "      #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)), ]\n",
    "        ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),]\n",
    "        #('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators=100, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1))]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { #'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "   'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,40],'learning_rate': [0.1,0.5,1],\n",
    "    'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,50,100]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CO2, Algorithm LGBM_total, Test_r2 0.9536183826186982, Test_error 0.7113135916736755\n",
      "Dataset CFCs, Algorithm LGBM_total, Test_r2 0.9363822193470825, Test_error 0.7059890712883428\n",
      "Dataset Methane, Algorithm LGBM_total, Test_r2 0.9240358072595617, Test_error 0.9205922930130099\n",
      "Dataset E&E, Algorithm LGBM_total, Test_r2 0.9482950590702367, Test_error 0.40657639157088615\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './new_LOO_Four gases_Total_result_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20168/1105017435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_comparison\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpara_grids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mfiles_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'new_LOO_Four gases_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_result_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfiles_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;31m#pd.DataFrame(results,columns = ['Gas','Algo','Train_erro','Test_error']).to_csv(os.path.join('./',files_name))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_optuna\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_optuna\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_optuna\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_optuna\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './new_LOO_Four gases_Total_result_0.csv'"
     ]
    }
   ],
   "source": [
    "feature_1 = ['V','S','L','BET','Vt','Temp(K)','Pressure']\n",
    "feature_2 = ['V','S','L','BET','Vt',\"Vmeso\",'Temp(K)','Pressure']\n",
    "feature_3 = ['V','S','L','BET','Vt',\"Vmic\",'Temp(K)','Pressure']\n",
    "feature_4 = ['V','S','L','BET','Vt','Vmeso','Temp(K)','Pressure']\n",
    "feature_list = [feature_1,feature_2,feature_3,feature_4]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "file_name = ['Total',\"Meso\",\"Micro\",'All']\n",
    "for i in range(1):\n",
    "    #train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'])\n",
    "    #train_df.to_csv(os.path.join('./Splitted_data/',str(i)+'_train_df.csv'))\n",
    "    #test_df.to_csv(os.path.join('./Splitted_data/',str(i)+'_test_df.csv'))\n",
    "    for j in range(0,1):\n",
    "        results = model_comparison(models,para_grids, feature_list[j])\n",
    "        files_name = 'new_LOO_Four gases_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(results,columns = columns).to_csv(os.path.join('./',files_name))  \n",
    "        #pd.DataFrame(results,columns = ['Gas','Algo','Train_erro','Test_error']).to_csv(os.path.join('./',files_name))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "    \n",
    "    #lpgo.get_n_splits(groups=groups)\n",
    "    out_cv = LeavePGroupsOut(n_groups=1)\n",
    "    #out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list):\n",
    "    gas_list = ['total','CO2','CFCs','Methane','E&E']\n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "        if gas =='total':\n",
    "\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index'].values\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                \n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "\n",
    "                print(result)\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                for gases in gas_list[1:]:\n",
    "                    test_df_com = test_df[test_df['Label']==gases]\n",
    "                    test_xs = test_df_com[input_feature]\n",
    "                    test_ys = test_df_com[output].values\n",
    "                    test_r2,test_mse = model_eval(model_refit,test_xs,test_ys.squeeze()) \n",
    "                    result_total.append([gases,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "           \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "  \n",
    "n_estimators = [50,100,150,200,250,300]\n",
    "\n",
    "# define different models#('SVR',SVR(max_iter=10000)),\n",
    "models = [#('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "     #('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "     # (\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "      #('BG',BaggingRegressor(random_state=42,n_jobs=-1)), \n",
    "      # ('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "      #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)), ]\n",
    "        ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),]\n",
    "       # ('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators=100, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1))]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { #'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "   'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,40,50,60],'learning_rate': [0.01,0.05,0.1,0.5,1],\n",
    "    'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,50,100]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2528 out of 2543 | elapsed:  1.0min remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7253279255320467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2543 out of 2543 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "gas_list = ['total','CO2','CFCs','Methane','E&E']\n",
    "input_feature = ['V','S','L','BET','Vt','Temp(K)','Pressure']\n",
    "output = ['Adsorp(mmol/g)']\n",
    "train_df_com = train_df\n",
    "#test_df_com = test_df\n",
    "train_x = train_df_com[input_feature]\n",
    "#test_x = test_df_com[input_feature]\n",
    "train_y = train_df_com[output].values\n",
    "#test_y = test_df_com[output].values\n",
    "groups = train_df_com['Index'].values\n",
    "#train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "             \n",
    "for model_name, model in models:\n",
    "\n",
    "    out_cv = LeavePGroupsOut(n_groups=1)\n",
    "    train_cv = cross_validate(model,train_x,train_y.squeeze(),cv =out_cv.get_n_splits(groups =groups),scoring = ('r2', 'neg_mean_squared_error'),n_jobs =-1,verbose=1)\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 4.000e+00, 2.000e+00, 2.000e+00, 1.000e+00, 7.000e+00,\n",
       "        1.400e+01, 4.100e+01, 1.140e+02, 2.357e+03]),\n",
       " array([-2.29171038e+01, -2.06255637e+01, -1.83340237e+01, -1.60424837e+01,\n",
       "        -1.37509437e+01, -1.14594037e+01, -9.16786370e+00, -6.87632369e+00,\n",
       "        -4.58478368e+00, -2.29324367e+00, -1.70365798e-03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_cv['test_neg_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.91710375590229"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cv['test_neg_mean_squared_error'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm LGBM, Test_r2 0.9500334997948807, Test_error 0.6800173312818948\n"
     ]
    }
   ],
   "source": [
    "gas_list = ['total','CO2','CFCs','Methane','E&E']\n",
    "input_feature = ['V','S','L','BET','Vt','Vmic','Vmeso','Temp(K)','Pressure']\n",
    "output = ['Adsorp(mmol/g)']\n",
    "train_df_com = train_df\n",
    "#test_df_com = test_df\n",
    "train_x = train_df_com[input_feature].values\n",
    "#test_x = test_df_com[input_feature]\n",
    "train_y = train_df_com[output].values\n",
    "model = LGBMRegressor(n_estimators=300,learning_rate=0.1,num_leaves=20,n_jobs = -1,random_state = 42)\n",
    "out_cv = LeavePGroupsOut(n_groups=1)\n",
    "train_y_real = np.array([])\n",
    "train_y_pred = np.array([])\n",
    "train_y_label = np.array([])\n",
    "labels = train_df_com['Label'].values\n",
    "\n",
    "for train_index, test_index in out_cv.split(train_x, train_y, groups):\n",
    "\n",
    "    \n",
    "    X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "    y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "    test_label = labels[test_index]\n",
    "            \n",
    "    model.fit(X_train,y_train.squeeze())\n",
    "    temp_pred = model.predict(X_test)\n",
    "    train_y_real = np.append(train_y_real,y_test)\n",
    "    train_y_pred = np.append(train_y_pred,temp_pred)\n",
    "    train_y_label = np.append(train_y_label,test_label)\n",
    "        \n",
    "LOO_mse = mean_squared_error(train_y_real,train_y_pred)\n",
    "LOO_r2  = r2_score(train_y_real,train_y_pred)\n",
    "    #return LOO_r2,LOO_mse\n",
    "print('Algorithm {}, Test_r2 {}, Test_error {}'.format(model_name,LOO_r2,LOO_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CO2, Algorithm LGBM_total, Test_r2 0.9562962907428596, Test_error 0.6702448977920076\n",
      "Dataset CFCs, Algorithm LGBM_total, Test_r2 0.9518096421443186, Test_error 0.5347854898176997\n",
      "Dataset Methane, Algorithm LGBM_total, Test_r2 0.9300525388065435, Test_error 0.8476769299786685\n",
      "Dataset E&E, Algorithm LGBM_total, Test_r2 0.9493564522255586, Test_error 0.3982302375792384\n"
     ]
    }
   ],
   "source": [
    "new_df =pd.DataFrame()\n",
    "new_df['Y_real'] = train_y_real\n",
    "new_df['Y_pred'] = train_y_pred\n",
    "new_df['Label']  = train_y_label\n",
    "for gas in gas_list[1:]:\n",
    "    test_df_com = new_df[new_df['Label']==gas]\n",
    "    test_xs = test_df_com['Y_real'].values\n",
    "    test_ys = test_df_com['Y_pred'].values\n",
    "    test_r2,test_mse = r2_score(test_xs,test_ys),mean_squared_error(test_xs,test_ys)\n",
    "    #result_total.append([gas,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
