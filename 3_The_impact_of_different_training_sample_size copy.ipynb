{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predicting adsorption for each adsorption data point using Vt and BET only focusing on the impact of different training sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def pred_dataset(file_names, feature_set ):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        print(len(index))\n",
    "        #test_index= np.random.choice(index,int(0.1*len(index)),replace=False)\n",
    "        test_index= np.random.choice(index,25,replace=False)\n",
    "        train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        \n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "from sklearn.svm import SVR\n",
    "#from xgboost import XGBRegressor\n",
    "\n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "\n",
    "# define different models#,\n",
    "models = [\n",
    "    #('SVR',SVR(max_iter=100000)),\n",
    "    #('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "    # ('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "    #(\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('BG',BaggingRegressor(random_state=42,n_jobs=-1)),\n",
    "    ('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)),\n",
    "    ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    ('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    ('XGBR',XGBRegressor(eta=0.1, subsample=0.7, colsample_bytree=0.8,random_state =42))\n",
    "    #('BGETR',BaggingRegressor(ExtraTreesRegressor(n_estimators = 180,random_state=42,n_jobs=6),random_state=42,n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { \n",
    "    'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "    'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]},\\\n",
    "    'BGETR':{'n_estimators':[10]},\\\n",
    "    'XGBR':{'n_estimators':n_estimators, 'max_depth':[2,4,6,8,10],}\n",
    "      \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "           \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_separate',test_r2,test_mse))\n",
    "\n",
    "                \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "25\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.6710063485262785, Test_error 2.296857462190462\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.821623505766514, Test_error 1.5991057213204904\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8237523297309143, Test_error 1.5685836243671645\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.6648345749988451, Test_error 2.240071270917598\n",
      "50\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.7558400900900114, Test_error 2.0762371562118633\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8671490937468458, Test_error 1.4792001873222735\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8288537652993834, Test_error 1.6531739869135813\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.6758991463321662, Test_error 2.5261031184128915\n",
      "75\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.7341203668657469, Test_error 2.165920833583289\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.7351272471012846, Test_error 3.099444903182974\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.7765106908780125, Test_error 2.258810306501356\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.6684548123864564, Test_error 2.3768227203377363\n",
      "100\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8314396714750736, Test_error 1.5188092112700535\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8378257709087251, Test_error 1.7079514956563568\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8398627104025678, Test_error 1.4963931305633502\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8006095016421868, Test_error 1.6842434458296933\n",
      "125\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8279650019545631, Test_error 1.5707253519938589\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.7430799236591644, Test_error 2.4060325500942445\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8113101900684583, Test_error 1.6366618237896327\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.7814540713356524, Test_error 1.6772438679875976\n",
      "150\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9206319496859389, Test_error 0.9065308358492075\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8867023052286153, Test_error 1.4662164010922487\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8948036255064372, Test_error 1.247131929134061\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8996535348338899, Test_error 1.000756541084618\n",
      "175\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8638168075639501, Test_error 1.6201530937201425\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8609730533411519, Test_error 1.866392065677555\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8529016730502266, Test_error 1.7909753266299129\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8737333895937033, Test_error 1.1956380212242588\n",
      "200\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8882548943557262, Test_error 1.0647835044743432\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8544610802968126, Test_error 1.4893892546721303\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9031532163753098, Test_error 0.958340812035144\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8009958313880591, Test_error 1.5731516570562731\n",
      "225\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8879352434000746, Test_error 1.063342079562046\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.934699280578278, Test_error 0.6558494389419671\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9314786923144662, Test_error 0.7074638681341229\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9163672602584676, Test_error 0.7806651761738926\n",
      "250\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8957889482127515, Test_error 1.0043542619441934\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8801233329189261, Test_error 1.299351114198361\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8802023668983218, Test_error 1.2058046697860063\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8362915109511364, Test_error 1.3451359220229173\n",
      "275\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.873169340194498, Test_error 1.3349526641068452\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.855541581375719, Test_error 1.4519994237661007\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8521653837923321, Test_error 1.5267893663251624\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8497252436769069, Test_error 1.4122312917812498\n",
      "300\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8837582920632316, Test_error 1.1176308263680252\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9051555153214043, Test_error 0.9836334602620936\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9077227226253552, Test_error 0.9281046805957515\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.876160842447319, Test_error 1.0815698040496537\n",
      "325\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8297534961315458, Test_error 1.7374984515742347\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.830041914041137, Test_error 1.863298333683817\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8409449211035576, Test_error 1.7139944670275833\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.7895721829599189, Test_error 1.895438832721698\n",
      "350\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8646450739931397, Test_error 1.2489910668815976\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8611561632988166, Test_error 1.4341389125912856\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8748963837913373, Test_error 1.1981655104662796\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8448227805919033, Test_error 1.3210068466061073\n",
      "375\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8629252173892935, Test_error 1.2092005658825733\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8219644435014122, Test_error 1.7696687082846922\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8793689194916339, Test_error 1.1785000335313913\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.7566993911657787, Test_error 1.8907802563709093\n",
      "400\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9130197909862309, Test_error 0.8683039307099741\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9058427386962243, Test_error 1.0018632161134178\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.928028676842958, Test_error 0.7788088452632782\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8778652643979359, Test_error 1.1165705081878519\n",
      "425\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9043090830135205, Test_error 0.9508090830530125\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.92072951180307, Test_error 0.7823220744821398\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9030524960238288, Test_error 0.9387754764054305\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.873459242226343, Test_error 1.0420009920649387\n",
      "450\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9050291831764689, Test_error 1.0571417685047573\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9057153720906288, Test_error 1.1375755170542423\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9221914845792822, Test_error 0.8965172981934363\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8903865673533841, Test_error 1.1206410031267404\n",
      "475\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8608322494218027, Test_error 1.3521559957487168\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8881065701548257, Test_error 1.1745538852362565\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8945085309759637, Test_error 1.0414917612398376\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8472200099671701, Test_error 1.3423566737944548\n",
      "500\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8869497257219218, Test_error 1.201559640358366\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8952673656285296, Test_error 1.134270101409344\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9111816950036556, Test_error 0.9322080426003899\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8563285657552369, Test_error 1.3128142208175295\n",
      "525\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9109600897617092, Test_error 0.8689429586812732\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9085457388017784, Test_error 0.8877893821067273\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9325465657276617, Test_error 0.6858924675300755\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8655805999924849, Test_error 1.1334775765988259\n",
      "550\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9047739860880334, Test_error 0.9588524172886649\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.892189843069822, Test_error 1.1405742245979247\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9024973448392962, Test_error 1.0024877970334445\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8611992079954593, Test_error 1.2322391715258132\n",
      "575\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9051109480008762, Test_error 0.9500834304300745\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9040584149274049, Test_error 0.9492400767893441\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.934799050422744, Test_error 0.6651483474827794\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.834847765945392, Test_error 1.3476713564167726\n",
      "600\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8989007563258882, Test_error 1.0298644545773394\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9096883321943046, Test_error 0.9351854145289915\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9169069328005109, Test_error 0.8558517935740143\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8882046838060959, Test_error 1.0237617153816567\n",
      "625\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9128719415061762, Test_error 0.8871306584822947\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9282112712265801, Test_error 0.7172966704826902\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9349091836174481, Test_error 0.6533928410956422\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8961578184656824, Test_error 0.9106483058001583\n",
      "650\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9195900497500995, Test_error 0.8844516663515026\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9187384803787318, Test_error 0.8989523777705966\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9289446921335118, Test_error 0.7853477176157858\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8672297795060604, Test_error 1.2259409986820742\n",
      "675\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9182472792161365, Test_error 0.8035331496482331\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9246578415480351, Test_error 0.7620861521013039\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9267410131170313, Test_error 0.7275374027085518\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8587413223167729, Test_error 1.2080968444638758\n",
      "700\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.914480893570301, Test_error 0.9097579269569979\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9270289002303727, Test_error 0.8588505825070826\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9286119758148537, Test_error 0.7538197497317739\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.89083055330585, Test_error 0.9703626838299043\n",
      "725\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9170144438903143, Test_error 0.8586208417463506\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9016119476863654, Test_error 1.054786771606511\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9404153339498198, Test_error 0.6161075571443879\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8646340198401082, Test_error 1.2069168282350033\n",
      "750\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9139683069845702, Test_error 0.8822950558158172\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8974803204899777, Test_error 1.1148183849114943\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9317696808287111, Test_error 0.6925733459436043\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8693470828237083, Test_error 1.1382854958320443\n",
      "775\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9114269263240643, Test_error 0.888137381145885\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9193475084812218, Test_error 0.8378491888903471\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9369181111967884, Test_error 0.6386337132562039\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8189676106992986, Test_error 1.4244528218539623\n",
      "820\n",
      "25\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.7153586011707355, Test_error 2.3165007627992997\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.826731315889412, Test_error 1.7256310679059583\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8105552804530973, Test_error 1.9234725860239226\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.7696607460417275, Test_error 1.9720828536978103\n",
      "50\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8119100882928677, Test_error 1.6977222020963132\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.775584606422712, Test_error 2.439277792111027\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.7892082037480775, Test_error 1.991854077010698\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.732572229474877, Test_error 2.1624399429557903\n",
      "75\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8608462737808193, Test_error 1.768013470912145\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8018777146549716, Test_error 2.536816860407724\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8627791000724765, Test_error 1.7512399540553394\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8688880695989876, Test_error 1.435767573454738\n",
      "100\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8588545577450298, Test_error 1.4716520686180459\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8597644824298951, Test_error 1.6198638961864296\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8648074089485329, Test_error 1.6371011078912776\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8254387453765446, Test_error 1.9723060208584795\n",
      "125\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8902428690733861, Test_error 1.1228396818617936\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8750683614406933, Test_error 1.4576469080218175\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8781930175926419, Test_error 1.3706554943447238\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8896628600295302, Test_error 1.261397852515269\n",
      "150\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.897324028359256, Test_error 1.162564032509628\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8694746229711859, Test_error 1.4236978023526161\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8948537847374883, Test_error 1.145316826072062\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8298886827365133, Test_error 1.7105768444636058\n",
      "175\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8989580214859931, Test_error 1.0819465444126863\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8588882961333308, Test_error 1.5620353641342999\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8947292356053326, Test_error 1.185241614106601\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8947252939617655, Test_error 1.1363565802051867\n",
      "200\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8997695991442948, Test_error 1.0721019443219197\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8910525070894929, Test_error 1.4104849900289576\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.888521588999836, Test_error 1.345435775911451\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8830128208853233, Test_error 1.2821756101708655\n",
      "225\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9289138295108089, Test_error 0.9190975814663442\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9274812649728553, Test_error 0.9979967351763087\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9303223051847176, Test_error 0.9487339055196439\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9260593135036173, Test_error 0.8796785256754833\n",
      "250\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8851903762423614, Test_error 1.0995650397826493\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.903618388576043, Test_error 0.9472005453368342\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9083671495622535, Test_error 0.9330580554064645\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8853385141551198, Test_error 1.065974385914843\n",
      "275\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9118364701419982, Test_error 0.9790479017409156\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9069792571217234, Test_error 1.0776058510957387\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9260254728068147, Test_error 0.8131677901955984\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8833722744554912, Test_error 1.0936600040723727\n",
      "300\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9039507882348479, Test_error 0.9850934190458456\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9001557990243227, Test_error 1.0227201196200164\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8977799308702357, Test_error 1.0486417412213276\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.91256678999725, Test_error 0.8880362483800183\n",
      "325\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.925538800686835, Test_error 0.8246026492864771\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9118533683243295, Test_error 1.020527849234799\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9226451053960556, Test_error 0.9347038574997518\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8702264920910956, Test_error 1.213011835688407\n",
      "350\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9174919384480117, Test_error 0.9005711310730304\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8987020182555647, Test_error 1.1879926178682958\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9238379188697672, Test_error 0.9302576444711242\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9362843863544559, Test_error 0.6907195569676434\n",
      "375\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9275100189661781, Test_error 0.8137981923486804\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9019283035061941, Test_error 1.0647665966953235\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9306704616116929, Test_error 0.8390363545706025\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9244661427683553, Test_error 0.7974824648609932\n",
      "400\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9236461935068161, Test_error 0.8730636475928186\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9047546904477748, Test_error 1.2693440121507498\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.93173758960574, Test_error 0.8841746663566111\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9016813551900343, Test_error 0.9761749035463823\n",
      "425\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9210678641979531, Test_error 0.8635691085737428\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9295825809728069, Test_error 0.7737671211629261\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9303374809189983, Test_error 0.8126198316022527\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9169365727683471, Test_error 0.9093034445808258\n",
      "450\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9310218054991402, Test_error 0.741203242776007\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9408178017822664, Test_error 0.6789868832113032\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9423693600390899, Test_error 0.6795262883031573\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9475566018800969, Test_error 0.5691539715376522\n",
      "475\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9335617583553164, Test_error 0.7251189029954483\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9426925527144235, Test_error 0.6887563101823436\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9478898323152105, Test_error 0.6320941451916221\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9548200886293591, Test_error 0.48819323600039616\n",
      "500\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9140648022632732, Test_error 0.9620239590624287\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9379963870736172, Test_error 0.7924634376334293\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9164066644528425, Test_error 0.984849929749815\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9252757584233237, Test_error 0.8103290370723213\n",
      "525\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9422972725651122, Test_error 0.6236838191931728\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9284226058912943, Test_error 0.8480223785964328\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9407792992172163, Test_error 0.6878500270713975\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9026426512417257, Test_error 0.9589132047506584\n",
      "550\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9266363978352103, Test_error 0.7731809255807862\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.893696582274927, Test_error 1.1043536940390712\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9155573889719462, Test_error 0.9363479178694163\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8968299787882158, Test_error 0.9862893604276961\n",
      "575\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9301825944632235, Test_error 0.7354511901501126\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9346866830401093, Test_error 0.7366235837775782\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9403751897293164, Test_error 0.6589369919900202\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9287149752570636, Test_error 0.7442366608232972\n",
      "600\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9190685101518289, Test_error 0.8481115694414031\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9293596514804197, Test_error 0.720912623893721\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9374819691756983, Test_error 0.679591473739468\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9110543148176647, Test_error 0.9193600690343315\n",
      "625\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9374385404893798, Test_error 0.6879168308921189\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9257352578710137, Test_error 0.8460727653942844\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9354978384253765, Test_error 0.719323626923967\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9276281702574994, Test_error 0.7607727258467792\n",
      "650\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9227478865479687, Test_error 0.8158089101672026\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9419224356399919, Test_error 0.6723269921541266\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.937719749341106, Test_error 0.7006831758454786\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9154287551641405, Test_error 0.8270374100615134\n",
      "675\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9284044906146832, Test_error 0.7427010377055903\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9263381621030327, Test_error 0.7942530339658445\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9367363137154365, Test_error 0.708942985948969\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9191515998886797, Test_error 0.8253487293399232\n",
      "700\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9389064666002289, Test_error 0.671298330859188\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9369206182487158, Test_error 0.7370163573065568\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9453344165794104, Test_error 0.6252498125528332\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.94003331104765, Test_error 0.6493845439559657\n",
      "725\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9330175278898328, Test_error 0.7267572945894589\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9360919616418898, Test_error 0.7550160276394169\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9401226575122265, Test_error 0.7100424030144976\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9394544737461876, Test_error 0.6994424873362688\n",
      "750\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9268303362646828, Test_error 0.7528233323342762\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9172523934890908, Test_error 0.8484977517184926\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9388085721861729, Test_error 0.6720067354835187\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8992655053723777, Test_error 0.9333273468266086\n",
      "775\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9271521307811031, Test_error 0.754557717719901\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9384651805217132, Test_error 0.6501336154178106\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9398165124473001, Test_error 0.6639370553075228\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9081577411866533, Test_error 0.883629602435498\n",
      "820\n",
      "25\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 -0.09183784942453932, Test_error 8.799835032919065\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 -0.4887981035117701, Test_error 12.355430963000968\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 -0.2169341156798943, Test_error 10.190201761877344\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.08577075033211001, Test_error 8.156668308492751\n",
      "50\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.09525431264094475, Test_error 7.53086964429112\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 -0.08857503252149468, Test_error 8.555944141183698\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 -0.044030076450823685, Test_error 8.106898412647297\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 -0.4765703884074486, Test_error 9.324002239153517\n",
      "75\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.44834904336421977, Test_error 5.385549877812831\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.5389572828867406, Test_error 5.277393589883188\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.4537478503297747, Test_error 5.616409434414186\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.2986968073027817, Test_error 6.162689526789678\n",
      "100\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8813116659258756, Test_error 1.8330222654591688\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8739049861043475, Test_error 2.126946206073979\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8947486731405786, Test_error 1.723852824177357\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9149841774602345, Test_error 1.4699990204349982\n",
      "125\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9155080906986283, Test_error 1.584444660872409\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9000851960878126, Test_error 1.9483654141425617\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8969005691101966, Test_error 1.9712536535442313\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8983964787368436, Test_error 1.8932384365061017\n",
      "150\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9187058461938237, Test_error 1.5449868056892075\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8654221866547978, Test_error 2.67814205713181\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8791590352114091, Test_error 2.3112189253736335\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9144605585299427, Test_error 1.6716017825742953\n",
      "175\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.3025590817776663, Test_error 6.258762572224095\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.49551795736903437, Test_error 5.367947927908422\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.24546241162626015, Test_error 6.596533046072386\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 -0.08060748869012602, Test_error 7.965117930079148\n",
      "200\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9228018616070672, Test_error 1.34268330806165\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8958393867143739, Test_error 1.8266939540662859\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8977654620362948, Test_error 1.67235136672219\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8947777123197898, Test_error 1.8809831336792817\n",
      "225\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8805492005612744, Test_error 1.9821940484458827\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8660131434431468, Test_error 2.3422344212731905\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8716019976664943, Test_error 2.1887102451882985\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8539449580792234, Test_error 2.425330635664132\n",
      "250\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9268295853358496, Test_error 1.3621302446250885\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9076473150164026, Test_error 1.8196909404150037\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9182085411818994, Test_error 1.5565706677555973\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9181642456152678, Test_error 1.6481200078092464\n",
      "275\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8834312309811676, Test_error 1.8658518892543694\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8580118934170734, Test_error 2.432736724435132\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8885650187244285, Test_error 1.876473582977391\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8789168482614965, Test_error 1.9313506119137493\n",
      "300\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8987475131476994, Test_error 1.8159355556581422\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.913016776923461, Test_error 1.6759496687900293\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9030361331496639, Test_error 1.753640303790378\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8898577148790656, Test_error 1.8702914518851934\n",
      "325\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.922411779950872, Test_error 1.3981076593814896\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9238914858972403, Test_error 1.4015500568631964\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9212900818199433, Test_error 1.4533749095174555\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8737763344426439, Test_error 2.3816941612209233\n",
      "350\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8993913713027668, Test_error 1.7372820810209448\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9018761019774555, Test_error 1.8143550471760252\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9250550386720636, Test_error 1.418475840533458\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8835965301616929, Test_error 1.9475139357384674\n",
      "375\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.8812516794970211, Test_error 1.8465874970709484\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.856100015573123, Test_error 2.466906427032961\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.8845818244864436, Test_error 1.9211343177810936\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.8602594259936456, Test_error 2.1028724495362825\n",
      "400\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9353862049465891, Test_error 1.1943941317359683\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9373975998511339, Test_error 1.2492438388034646\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9496863298511438, Test_error 0.9683412033499081\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9327332533744948, Test_error 1.3090464374173798\n",
      "425\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9288987287418443, Test_error 1.2831695816269815\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9396270574593493, Test_error 1.2413659068087686\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9322432694968126, Test_error 1.30273078518013\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.9267918151603987, Test_error 1.4152818238860796\n",
      "450\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9322839388961869, Test_error 1.2518317512821926\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9283856201992676, Test_error 1.411453484195359\n",
      "Dataset Methane, Algorithm BGLGBM_separate, Test_r2 0.9417618546681007, Test_error 1.0973255908829511\n",
      "Dataset Methane, Algorithm XGBR_separate, Test_r2 0.913173596662518, Test_error 1.6774504203263538\n",
      "475\n",
      "Dataset Methane, Algorithm ETR_separate, Test_r2 0.9144192275966114, Test_error 1.6038597761884634\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_3 = ['Vt',\"Vmic\",]\n",
    "combin_5 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_6 = [\"Vmic\",'Vmeso',]\n",
    "feature_list = [base_feature+combin_1+condition_feature]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "#file_name = ['Total',\"Meso\",\"Micro\",'All','Vmic_meso']\n",
    "file_name = ['BET_plut_Vt']\n",
    "feature_set = [\"Vt\",]\n",
    "gas_list = ['Methane']\n",
    "fraction = [1,2,3,4,5,6,7,8,9]\n",
    "for i in range(10):\n",
    "    train_dfs,test_df = pred_dataset(gas_list,feature_set)#\n",
    "    fraction = range(25,len(list(set(train_dfs[\"Index\"].values))),25)\n",
    "    for k in fraction:\n",
    "        print(k)\n",
    "        temp_df = train_dfs\n",
    "        nums_test = len(list(set(test_df[\"Index\"].values)))\n",
    "        index = list(set(temp_df['Index'].values))\n",
    "        #print(len(index))\n",
    "        train_index= np.random.choice(index,k,replace=False)\n",
    "        train_df = temp_df.loc[temp_df['Index'].isin(train_index)]\n",
    "        \n",
    "        results = model_comparison(models,para_grids, feature_list[0],gas_list)\n",
    "        files_name = 'The_impact_of_different_training_sample_size_of_'+str(k)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(results,columns = columns).to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatments\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = ['BET_plut_Vt','BET_only',]\n",
    "\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for j in  range(25,len(list(set(train_dfs[\"Index\"].values))),25):\n",
    "    df_list = []\n",
    "    for i in range(10):\n",
    "    \n",
    "        files_name = 'The_impact_of_different_training_sample_size_of_'+str(j)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "        df_list.append(pd.read_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name))[cal_columns] )\n",
    "    pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./3_The_impact_of_different_training_sample_size','Training_size_of_'+str(j)+'_mean.csv'))\n",
    "    pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./3_The_impact_of_different_training_sample_size','Training_size_of_'+str(j)+'std.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame()\n",
    "for j in  range(25,len(list(set(train_dfs[\"Index\"].values))),25):\n",
    "    \n",
    "    files_name = 'Training_size_of_'+str(j)+'std.csv'\n",
    "    temp = pd.read_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name))\n",
    "    total = pd.concat([total,temp],axis =0)\n",
    "total.to_csv(os.path.join('./3_The_impact_of_different_training_sample_size','Total'+'_std.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Using dataset (CO2, Methane, and E&E) with more datapoints to improve the prediction of dataset with less data points (CFCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pred_dataset(file_names, feature_set):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    data_df = pd.DataFrame()\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        #train_x,test_x = train_test_split(temp_data,test_size = 0.2)\n",
    "        data_df = pd.concat([data_df,temp_data],axis=0)\n",
    "        #test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pred_dataset(['Ethane&Ethylene'],['BET','Vt'])\n",
    "len(set(data[\"Index\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "  \n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "\n",
    "# define different models#,\n",
    "models = [\n",
    "    #('SVR',SVR(max_iter=100000)),\n",
    "    #('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "    # ('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "    #(\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('BG',BaggingRegressor(random_state=42,n_jobs=-1)),\n",
    "    ('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)),\n",
    "    ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    ('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    ('XGBR',XGBRegressor(eta=0.1, subsample=0.7, colsample_bytree=0.8,random_state =42))\n",
    "    #('BGETR',BaggingRegressor(ExtraTreesRegressor(n_estimators = 180,random_state=42,n_jobs=6),random_state=42,n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { \n",
    "    'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "    'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]},\\\n",
    "    'BGETR':{'n_estimators':[10]},\\\n",
    "    'XGBR':{'n_estimators':n_estimators, 'max_depth':[2,4,6,8,10],}\n",
    "      \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "            #train_df_com = train_df[train_df['Label']==gas]\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            print(f'With big set and the total training records is {len(train_df_com)}')\n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_with_big_set',test_r2,test_mse))\n",
    "\n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            print(f'With no big set and the total training records is {len(train_df_com)}')\n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_no_big_set',test_r2,test_mse))\n",
    "\n",
    "                \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def group_split(data_df,target,additional):\n",
    "    #np.random.seed(42)\n",
    "    temp_data = data_df[data_df[\"Label\"]==target]\n",
    "    index = list(set(temp_data['Index'].values))\n",
    "    temp_data,_ = shuffle(temp_data, temp_data['Index'].values, random_state=42)\n",
    "    #print(len(index))\n",
    "    test_index= np.random.choice(index,int(0.2*len(index)),replace=False)\n",
    "    train_df = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "    test_df = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "    index_len = len(list(set(train_df['Index'].values)))\n",
    "\n",
    "\n",
    "    for gas in additional:\n",
    "        temp_data = data_df[data_df[\"Label\"]==gas]\n",
    "        temp_index = list(set(temp_data['Index'].values))\n",
    "        if len(temp_index)<index_len*6:\n",
    "            train_df = pd.concat([train_df,temp_data])\n",
    "        else:\n",
    "            #selected_index =  np.random.choice(temp_index,index_len*3,replace=False)\n",
    "            selected_index =  np.random.choice(temp_index,388,replace=False) # for CO2 and Methane only\n",
    "            temp_train = temp_data.loc[temp_data['Index'].isin(selected_index)]\n",
    "            train_df = pd.concat([train_df,temp_train])\n",
    "    groups = train_df['Index'].values\n",
    "    train_df, groups = shuffle(train_df, groups, random_state=42)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "With big set and the total training records is 5230\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9575793692807911, Test_error 0.7395101865428176\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9396782196984502, Test_error 1.0759032718127106\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9406840633655214, Test_error 0.9009091139034522\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.893957020406485, Test_error 1.425373432705784\n",
      "With no big set and the total training records is 1295\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9545732602184712, Test_error 0.7630520088115674\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9463394003250634, Test_error 0.9105006160081432\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9404565532997785, Test_error 0.9332125440186539\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9384202798311716, Test_error 0.9410676209540155\n",
      "316\n",
      "With big set and the total training records is 5130\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9646266625021052, Test_error 0.43011045716537416\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9362490778838015, Test_error 0.8498134813745728\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9571782293520136, Test_error 0.502303392515909\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9459203829017274, Test_error 0.6010357863876262\n",
      "With no big set and the total training records is 1251\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9658901458631124, Test_error 0.4109056091413631\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9505883491696753, Test_error 0.6135260707710579\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9602997022600759, Test_error 0.4567039515192664\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9565729555813642, Test_error 0.5053185506047007\n",
      "306\n",
      "With big set and the total training records is 5179\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.939017265523817, Test_error 1.3418457077441843\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9477761960468006, Test_error 1.2476300790673989\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9413243996583864, Test_error 1.297734723862415\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9388555970516588, Test_error 1.2885610400380259\n",
      "With no big set and the total training records is 1261\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9234337485192126, Test_error 1.6047523252388436\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9483253230351723, Test_error 1.2250596739733788\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9475499337639821, Test_error 1.2442379209934773\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9055356881811032, Test_error 1.8277022121140294\n",
      "290\n",
      "With big set and the total training records is 5214\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9605103269110276, Test_error 0.8836726275596664\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.948024922169214, Test_error 1.3611868480348457\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.945438499595543, Test_error 1.1539456104367454\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.947551539103976, Test_error 1.0494884333080836\n",
      "With no big set and the total training records is 1277\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9446939606399324, Test_error 1.1959562458783983\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9466965162608492, Test_error 1.5169415661273111\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9533858058530598, Test_error 1.0363566780216182\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9512437122057018, Test_error 0.9822930233905336\n",
      "295\n",
      "With big set and the total training records is 5159\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.7586748408736295, Test_error 2.985436789247238\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.780629979424416, Test_error 3.4536288397220054\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.7622438468763951, Test_error 3.153428131779017\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.797626897309259, Test_error 2.9388799138094095\n",
      "With no big set and the total training records is 1272\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.7903323900635503, Test_error 3.070901900029969\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.8017149650056662, Test_error 4.487317174204386\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.7837163870937768, Test_error 3.9844235127962424\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.8213369315382145, Test_error 3.1598678505274234\n",
      "312\n",
      "With big set and the total training records is 5183\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9460766942656874, Test_error 0.6018547581163505\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9239894366616737, Test_error 0.83140888441947\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9433415877196546, Test_error 0.6342964079451493\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9573744490143031, Test_error 0.4761744627006965\n",
      "With no big set and the total training records is 1255\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9501016935921277, Test_error 0.5655732286814225\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9580638711802502, Test_error 0.510073555380929\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9372946978660374, Test_error 0.7472014598404942\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9579431759520657, Test_error 0.4811163165736207\n",
      "313\n",
      "With big set and the total training records is 5180\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9513533944333874, Test_error 0.7548059272889722\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9619163949636427, Test_error 0.64704819997542\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9525162861680493, Test_error 0.7274577428331479\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9529297640166545, Test_error 0.6960025821377074\n",
      "With no big set and the total training records is 1254\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9587591347506217, Test_error 0.6461804261003701\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9618603829717546, Test_error 0.6440100985666953\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.958219524759428, Test_error 0.646145111212024\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9702060000608518, Test_error 0.4792581205467712\n",
      "342\n",
      "With big set and the total training records is 5156\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.8496609427374826, Test_error 1.8913545859900343\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.8944383369389528, Test_error 1.25788061283762\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.8767415310181843, Test_error 1.4587340296778324\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.7725206802772367, Test_error 2.82115089068731\n",
      "With no big set and the total training records is 1225\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.8652359314119906, Test_error 1.6846592074313078\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.7953010457529612, Test_error 3.499688911853662\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.7628923916047606, Test_error 4.079049639291209\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.8181568025105487, Test_error 2.6094244727497595\n",
      "287\n",
      "With big set and the total training records is 5180\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.7962591812942504, Test_error 3.3819801942669523\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.845895213646573, Test_error 2.6047453913345446\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.8271065896953674, Test_error 2.8891203325382038\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.797085798332804, Test_error 3.5037466379186903\n",
      "With no big set and the total training records is 1280\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.81593735585761, Test_error 3.0631583090938457\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.8241604732240355, Test_error 4.362158333268316\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.7939099404867833, Test_error 4.715008527643531\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.8529116943688573, Test_error 2.7048526732148277\n",
      "284\n",
      "With big set and the total training records is 5223\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9706975546688098, Test_error 0.7799815641281492\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9504108765313094, Test_error 1.1850335770850435\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9597449700204733, Test_error 0.9448728824385705\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9654567755046526, Test_error 0.850383810534376\n",
      "With no big set and the total training records is 1283\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9715784001837645, Test_error 0.7488439596450236\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9491336720655834, Test_error 1.2160662907390534\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9712614470952994, Test_error 0.7198488396076643\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9752626402879372, Test_error 0.6262016138544995\n",
      "347\n",
      "With big set and the total training records is 5149\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9763507243264714, Test_error 0.3665924476813837\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9686453951737991, Test_error 0.5152041592528339\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9759224280842065, Test_error 0.35903720156375324\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9789728907902235, Test_error 0.32486363610219626\n",
      "With no big set and the total training records is 1220\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9683736375848346, Test_error 0.5009150702068371\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9793867921081267, Test_error 0.31134436281842437\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9810278529559936, Test_error 0.2712704275266786\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9846451378304473, Test_error 0.22346951403888402\n",
      "360\n",
      "With big set and the total training records is 5133\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9263296409926702, Test_error 0.7390542851713318\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9608861512219066, Test_error 0.507893158463696\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9384190143853847, Test_error 0.6942332892219407\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9388938771669535, Test_error 0.6980548835020047\n",
      "With no big set and the total training records is 1207\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9301615143656113, Test_error 0.7043585636592352\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9595125059765279, Test_error 0.5425590356555394\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9528182159809488, Test_error 0.5889767168186518\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9461891912904544, Test_error 0.6478585970923727\n",
      "328\n",
      "With big set and the total training records is 5115\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.9699502752964003, Test_error 0.5315705037698234\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9701489699474469, Test_error 0.5500979622756769\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9642288336369922, Test_error 0.6328860428340303\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9609831694986954, Test_error 0.6937521484090443\n",
      "With no big set and the total training records is 1239\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9694851206533855, Test_error 0.5435523191225539\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9775080363408843, Test_error 0.4379295806858365\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.970862785601563, Test_error 0.5264021902142462\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9719201227170204, Test_error 0.515150502130161\n",
      "316\n",
      "With big set and the total training records is 5206\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.955944443655022, Test_error 0.4041083171431738\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.9585580500854138, Test_error 0.40327301786444214\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9674843317237146, Test_error 0.2970820659188738\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.9674367337306837, Test_error 0.3064528965405078\n",
      "With no big set and the total training records is 1251\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.9580638512548478, Test_error 0.37928566533214214\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.9537039605473863, Test_error 0.43400975851876866\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.9602709290687458, Test_error 0.3629712744441613\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.9567589635377388, Test_error 0.3915670728220174\n",
      "342\n",
      "With big set and the total training records is 5129\n",
      "Dataset CFCs, Algorithm ETR_with_big_set, Test_r2 0.8665674830003308, Test_error 1.8103595027178674\n",
      "Dataset CFCs, Algorithm LGBM_with_big_set, Test_r2 0.8929158922863059, Test_error 1.7731117782869714\n",
      "Dataset CFCs, Algorithm BGLGBM_with_big_set, Test_r2 0.9103453412355266, Test_error 1.2497024748359482\n",
      "Dataset CFCs, Algorithm XGBR_with_big_set, Test_r2 0.8288351309908818, Test_error 2.352972916782799\n",
      "With no big set and the total training records is 1225\n",
      "Dataset CFCs, Algorithm ETR_no_big_set, Test_r2 0.8724576914615376, Test_error 1.6834802403500848\n",
      "Dataset CFCs, Algorithm LGBM_no_big_set, Test_r2 0.8534746458498464, Test_error 2.4126626977911605\n",
      "Dataset CFCs, Algorithm BGLGBM_no_big_set, Test_r2 0.8195336048593898, Test_error 3.1825241980002454\n",
      "Dataset CFCs, Algorithm XGBR_no_big_set, Test_r2 0.8677287441298287, Test_error 2.070641578771562\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_5 = ['Vt',\"Vmic\",]\n",
    "combin_6 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_7 = [\"Vmic\",'Vmeso',]\n",
    "\n",
    "feature_list = [base_feature+combin_1+condition_feature]\n",
    "\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "feature_set = [\"BET\",\"Vt\"]\n",
    "gas_list = ['CFCs']\n",
    "file_name = [\"BET_Vt_Vmic_meso\"]\n",
    "\n",
    "for i in range(15):\n",
    "    data_df = pred_dataset(['Methane','CFCs'],feature_set= feature_set)\n",
    "    for gas in gas_list:\n",
    "        train_df,test_df = group_split(data_df,gas,['Methane'])\n",
    "        print(len(test_df))\n",
    "        for j in range(len(feature_list)):\n",
    "            results = model_comparison(models,para_grids, feature_list[j],[gas])\n",
    "            files_name = 'Improving_small_with_big_set'+gas+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "            pd.DataFrame(results,columns = columns).to_csv(os.path.join('./4_Improving_small_set_with_big_set',files_name))  \n",
    "            #pd.DataFrame(results,columns = ['Gas','Algo','Train_erro','Test_error']).to_csv(os.path.join('./',files_name))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "file_name = [\"BET_Vt_Vmic_meso\"]\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for gas in gas_list:\n",
    "    df_list = [] \n",
    "    for i in range(15):\n",
    "        for j in range(len(feature_list)):\n",
    "            files_name  = 'Improving_small_with_big_set'+gas+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "            df_list.append(pd.read_csv(os.path.join('./4_Improving_small_set_with_big_set',files_name))[cal_columns] )\n",
    "    pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./4_Improving_small_set_with_big_set',   gas+'-mean.csv'))\n",
    "    pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./4_Improving_small_set_with_big_set',gas+'-std.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the fitted parameters of adsorption isotherms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pred_dataset(file_names, feature_set = feature_set):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-fitting-02-01-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        train_x,test_x = train_test_split(temp,test_size = 0.2)\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,model,para_grid):\n",
    "\n",
    "    \n",
    "    result = GridSearchCV(model,para_grid,cv= 5,\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,cv =5,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "        if gas =='total':\n",
    "\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y,random_state=42)\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                \n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                for gases in gas_list[1:]:\n",
    "                    test_df_com = test_df[test_df['Label']==gases]\n",
    "                    test_xs = test_df_com[input_feature]\n",
    "                    test_ys = test_df_com[output].values\n",
    "                    test_r2,test_mse = model_eval(model_refit,test_xs,test_ys.squeeze()) \n",
    "                    result_total.append([gases,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "           \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print(print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    ")\n",
    "                \n",
    "    return result_total"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
