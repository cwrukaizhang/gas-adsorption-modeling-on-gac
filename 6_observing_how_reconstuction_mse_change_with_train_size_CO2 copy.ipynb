{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def pred_dataset(file_names, feature_set ,i):\n",
    "    source_path = './CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        \n",
    "        test_index = shuffle(sorted(index),random_state=i)[:26]\n",
    "        #test_index= np.random.choice(index,55,replace=False)\n",
    "        train_x = temp_data.loc[~temp_data['Index'].isin(test_index)]#[1,2,3]\n",
    "        test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        \n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "\n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "# define different models#,\n",
    "models = [\n",
    "    #(\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    #('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { \n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]},\\\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error')) \n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(train_df,test_df,model_list,para_grids,feature_list,gas_list,selected_index = None):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "\n",
    "                gas_checkpoint = gas+'_checkpoint'\n",
    "                if not os.path.exists(gas_checkpoint):\n",
    "                    os.makedirs(gas_checkpoint)\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                if os.path.exists(gas_checkpoint) and gas+'_checkpoint.txt' not in os.listdir(gas_checkpoint) and len(train_df)>10*len(test_df):\n",
    "                    model_refit.booster_.save_model(os.path.join(gas_checkpoint,gas+'_checkpoint.txt'))     \n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                if os.path.isfile(os.path.join(gas_checkpoint,gas+'_checkpoint.txt')) and len(train_df)>10*len(test_df):\n",
    "                    \n",
    "                    train_df_incre = train_df.loc[train_df['Index'].isin(selected_index),:]\n",
    "                    train_x_incr = train_df_incre[input_feature]\n",
    "                    train_y_incr = train_df_incre[output].values\n",
    "                    model_incread = LGBMRegressor(n_jobs = -1,random_state = 42).fit(train_x_incr,train_y_incr.squeeze(),init_model = os.path.join(gas_checkpoint,gas+'_checkpoint.txt'))\n",
    "                    test_r2_increa,test_mse_increa = model_eval(model_incread,test_x,test_y.squeeze())\n",
    "                    model_incread.booster_.save_model(os.path.join(gas_checkpoint,gas+'_checkpoint.txt'))\n",
    "                if not os.path.isfile(os.path.join(gas_checkpoint,gas+'_checkpoint.txt')):\n",
    "                    test_r2_increa,test_mse_increa = -1,-1\n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,test_r2_increa,test_mse_increa,best_param])\n",
    "                \n",
    "                print('Dataset {}, Algorithm {}, Test_r2 {:.4f}, Test_error {:.4f}, Test_r2_incre {:.4f}, Test_error_incre {:.4f},'.format(gas,model_name+'_separate',test_r2,test_mse,test_r2_increa,test_mse_increa))           \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nrd\n",
    "from sklearn.decomposition import KernelPCA,SparsePCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from  collections import Counter\n",
    "\n",
    "def bgk_pca(train_df,test_df): \n",
    "    #np.random.RandomState(42)# using major voting approach to find the outliers in the test dataset\n",
    "    test_index = list(set(test_df[\"Index\"].values))\n",
    "    len_test = len(test_index)\n",
    "    train_index = list(set(train_df[\"Index\"].values))\n",
    "    #total_feature = [\"Index\",'V','L','BET','Vt','Temp(K)']\n",
    "    total_feature = [\"Index\",'BET','Vt','Temp(K)']\n",
    "    #pca_feature =  ['V','L','BET','Vt','Temp(K)']\n",
    "    pca_feature =  ['BET','Vt','Temp(K)']\n",
    "    num_feature = len(pca_feature)\n",
    "    removed_index = []\n",
    "    res = []\n",
    "    iters = 10\n",
    "    multi_mse = []\n",
    "    for i in range(iters):\n",
    "        mses = []\n",
    "        train_selected = train_df[train_df[\"Index\"].isin(nrd.choice(train_index,int(len(train_index)*0.75),replace=False))] # modified here change fixed len to a the fraction of the len of the training dataset.\n",
    "        data = pd.concat([test_df,train_selected])\n",
    "        sub_data = data[total_feature].drop_duplicates()\n",
    "        sub_data_scalered = MinMaxScaler().fit_transform(sub_data[pca_feature].values)\n",
    "        \n",
    "        \"\"\"adding lines to determine the number of components to achieve 0.99 threshold\"\"\"\n",
    "        kernel_pca = KernelPCA(kernel='poly',max_iter =100000,n_jobs =-1,gamma=1e-2,fit_inverse_transform=True,random_state=42)\n",
    "        kpca_transform = kernel_pca.fit_transform(sub_data_scalered.reshape(num_feature,-1))\n",
    "        explained_variance = np.var(kpca_transform, axis=0)\n",
    "        explained_variance_ratio = explained_variance / np.sum(explained_variance)\n",
    "        cumu_variance = np.cumsum(explained_variance_ratio)\n",
    "        n_components = np.where(cumu_variance>0.99)[0][0]+1\n",
    "        kernel_pca = KernelPCA(n_components=n_components,kernel='poly',max_iter =100000,n_jobs =-1,gamma=1e-2,fit_inverse_transform=True,random_state=42)\n",
    "        \"\"\" The end of adding new lines\"\"\"\n",
    "\n",
    "        sub_data_transformed = kernel_pca.fit_transform(sub_data_scalered.reshape(num_feature,-1))\n",
    "        reconstructed = kernel_pca.inverse_transform(sub_data_transformed.reshape(num_feature,-1))\n",
    "        for i in range(len(sub_data_scalered)):\n",
    "            mses.append(mean_squared_error(sub_data_scalered[i],reconstructed.reshape(-1,num_feature)[i]))\n",
    "            df_mse = pd.DataFrame(mses,columns = ['MSE'])\n",
    "        df_mse['Indexs'] = sub_data[\"Index\"].drop_duplicates().values\n",
    "        mean_mse = df_mse[\"MSE\"].mean()\n",
    "        test_mse_df = df_mse[df_mse[\"Indexs\"].isin(test_index)]\n",
    "        outlier_index = test_mse_df[test_mse_df[\"MSE\"]>3*mean_mse][\"Indexs\"].values.tolist()\n",
    "        removed_index.extend(outlier_index)\n",
    "        multi_mse.append(mean_mse)\n",
    "\n",
    "    counter = Counter(removed_index)\n",
    "    thresh = int(0.7*iters)\n",
    "    for key,values in counter.most_common():\n",
    "        if values>=thresh:\n",
    "            res.append(key)\n",
    "            \n",
    "        if values<thresh: break\n",
    "\n",
    "    return np.mean(multi_mse)#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26 50\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.6397, Test_error 3.4537, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0357\n",
      "1 26 75\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.7074, Test_error 3.2236, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0374\n",
      "2 26 100\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.6495, Test_error 3.6376, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0355\n",
      "3 26 125\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8021, Test_error 2.1913, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0355\n",
      "4 26 150\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8511, Test_error 1.7389, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0314\n",
      "5 26 175\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8409, Test_error 1.8463, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0336\n",
      "6 26 200\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8406, Test_error 1.7670, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0341\n",
      "7 26 225\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8572, Test_error 1.6817, Test_r2_incre -1.0000, Test_error_incre -1.0000,\n",
      "recons_mse: 0.0308\n",
      "8 26 250\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8506, Test_error 1.7575, Test_r2_incre 0.8522, Test_error_incre 1.7561,\n",
      "recons_mse: 0.0291\n",
      "9 26 275\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8711, Test_error 1.5376, Test_r2_incre 0.8440, Test_error_incre 2.7341,\n",
      "recons_mse: 0.0291\n",
      "10 26 300\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8408, Test_error 1.9048, Test_r2_incre 0.8284, Test_error_incre 2.3862,\n",
      "recons_mse: 0.0300\n",
      "11 26 325\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8785, Test_error 1.5547, Test_r2_incre 0.5868, Test_error_incre 4.3326,\n",
      "recons_mse: 0.0301\n",
      "12 26 350\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8624, Test_error 1.6484, Test_r2_incre 0.6261, Test_error_incre 4.3602,\n",
      "recons_mse: 0.0285\n",
      "13 26 375\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8616, Test_error 1.6932, Test_r2_incre 0.5894, Test_error_incre 4.3913,\n",
      "recons_mse: 0.0312\n",
      "14 26 400\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8935, Test_error 1.3516, Test_r2_incre 0.2475, Test_error_incre 7.5538,\n",
      "recons_mse: 0.0301\n",
      "15 26 425\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8848, Test_error 1.4066, Test_r2_incre 0.2399, Test_error_incre 7.3100,\n",
      "recons_mse: 0.0304\n",
      "16 26 450\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8927, Test_error 1.3346, Test_r2_incre 0.0508, Test_error_incre 9.1897,\n",
      "recons_mse: 0.0277\n",
      "17 26 475\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8827, Test_error 1.4672, Test_r2_incre 0.2247, Test_error_incre 8.8792,\n",
      "recons_mse: 0.0287\n",
      "18 26 500\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.8927, Test_error 1.3866, Test_r2_incre 0.6397, Test_error_incre 5.0468,\n",
      "recons_mse: 0.0299\n",
      "19 26 525\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9090, Test_error 1.2312, Test_r2_incre 0.3442, Test_error_incre 6.9285,\n",
      "recons_mse: 0.0295\n",
      "20 26 550\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9024, Test_error 1.3308, Test_r2_incre 0.1944, Test_error_incre 7.6484,\n",
      "recons_mse: 0.0282\n",
      "21 26 575\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9183, Test_error 1.1145, Test_r2_incre 0.1681, Test_error_incre 8.7554,\n",
      "recons_mse: 0.0290\n",
      "22 26 600\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9107, Test_error 1.2546, Test_r2_incre 0.6393, Test_error_incre 6.2410,\n",
      "recons_mse: 0.0304\n",
      "23 26 625\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9211, Test_error 1.1300, Test_r2_incre 0.3851, Test_error_incre 7.0690,\n",
      "recons_mse: 0.0299\n",
      "24 26 650\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9011, Test_error 1.3735, Test_r2_incre 0.2980, Test_error_incre 7.6914,\n",
      "recons_mse: 0.0282\n",
      "25 26 675\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9189, Test_error 1.1191, Test_r2_incre 0.1582, Test_error_incre 8.1934,\n",
      "recons_mse: 0.0287\n",
      "26 26 700\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9361, Test_error 0.9326, Test_r2_incre 0.2433, Test_error_incre 8.8203,\n",
      "recons_mse: 0.0300\n",
      "27 26 725\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9397, Test_error 0.8597, Test_r2_incre 0.5273, Test_error_incre 7.0960,\n",
      "recons_mse: 0.0294\n",
      "28 26 750\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9258, Test_error 1.0387, Test_r2_incre 0.3941, Test_error_incre 8.7542,\n",
      "recons_mse: 0.0272\n",
      "29 26 775\n",
      "Dataset Methane, Algorithm LGBM_separate, Test_r2 0.9458, Test_error 0.7567, Test_r2_incre 0.5227, Test_error_incre 8.3420,\n",
      "recons_mse: 0.0284\n",
      "0 26 50\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'test_r2_increa' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m train_df \u001b[39m=\u001b[39m train_dfs\u001b[39m.\u001b[39mloc[train_dfs[\u001b[39m'\u001b[39m\u001b[39mIndex\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(train_index)]\n\u001b[1;32m     64\u001b[0m k_recon_mse \u001b[39m=\u001b[39m bgk_pca(train_df,test_df)\n\u001b[0;32m---> 65\u001b[0m results \u001b[39m=\u001b[39m model_comparison(train_df,test_df,models,para_grids, feature_list[\u001b[39m0\u001b[39;49m],gas_list,selected_index\u001b[39m=\u001b[39;49mselected_index)\n\u001b[1;32m     66\u001b[0m temp_results  \u001b[39m=\u001b[39m []\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m ele \u001b[39min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[28], line 69\u001b[0m, in \u001b[0;36mmodel_comparison\u001b[0;34m(train_df, test_df, model_list, para_grids, feature_list, gas_list, selected_index)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(gas_checkpoint,gas\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_checkpoint.txt\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m     68\u001b[0m                 test_r2_increa,test_mse_increa \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> 69\u001b[0m             result_total\u001b[39m.\u001b[39mappend([gas,model_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_separate\u001b[39m\u001b[39m'\u001b[39m,result[\u001b[39m0\u001b[39m],result[\u001b[39m1\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, test_r2,test_mse,test_r2_increa,test_mse_increa,best_param])\n\u001b[1;32m     71\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Algorithm \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, Test_r2 \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Test_error \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Test_r2_incre \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Test_error_incre \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(gas,model_name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_separate\u001b[39m\u001b[39m'\u001b[39m,test_r2,test_mse,test_r2_increa,test_mse_increa))           \n\u001b[1;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m result_total\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'test_r2_increa' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_3 = ['Vt',\"Vmic\",] \n",
    "combin_5 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_6 = [\"Vmic\",'Vmeso',]\n",
    "feature_list = [base_feature+combin_1+condition_feature]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param','kpg_pca_mse']\n",
    "#file_name = ['Total',\"Meso\",\"Micro\",'All','Vmic_meso']\n",
    "file_name = ['BET_plus_Vt']\n",
    "feature_set = [\"Vt\",]\n",
    "gas_list = ['Methane']\n",
    "'''\n",
    "for i in range(15):\n",
    "    train_dfs,test_df = pred_dataset(gas_list,feature_set)#\n",
    "    fraction = range(100,len(list(set(train_dfs[\"Index\"].values))),50)\n",
    "    for k in fraction:\n",
    "        print(k)\n",
    "        temp_df = train_dfs\n",
    "        nums_test = len(list(set(test_df[\"Index\"].values)))\n",
    "        index = list(set(temp_df['Index'].values))\n",
    "        #print(len(index))\n",
    "        train_index= np.random.choice(index,k,replace=False)\n",
    "        train_df = temp_df.loc[temp_df['Index'].isin(train_index)]\n",
    "        k_recon_mse = bgk_pca(train_df,test_df)\n",
    "        \n",
    "        results = model_comparison(models,para_grids, feature_list[0],gas_list)\n",
    "        temp_results  = []\n",
    "        for ele in results:\n",
    "            temp_results.append(ele+[k_recon_mse])\n",
    "        print(\"recons_mse: {:.4f}\".format(k_recon_mse))\n",
    "        files_name = 'Res_pca_The_impact_of_different_training_sample_size_of_'+str(k)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(temp_results,columns = columns).to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name)) \n",
    "'''\n",
    "\n",
    "for i in range(50):\n",
    "    recons_error = []\n",
    "    train_index = []\n",
    "    train_dfs,test_df = pred_dataset(gas_list,feature_set,i)#\n",
    "    nums_test = len(list(set(test_df[\"Index\"].values)))\n",
    "    index = list(set(train_dfs['Index'].values))\n",
    "    interval = 25\n",
    "\n",
    "    fraction = range(50,len(list(set(train_dfs[\"Index\"].values))),interval)\n",
    "    big_results = []\n",
    "    for k in range(len(fraction)):\n",
    "        if k==0:\n",
    "            selected_index = np.random.choice(index,50,replace=False)\n",
    "        else:\n",
    "            selected_index = np.random.choice(index,interval,replace=False)\n",
    "\n",
    "        for ele in selected_index:\n",
    "            index.remove(ele)\n",
    "        #print(len(index),print(train_index))\n",
    "        train_index.extend(selected_index) \n",
    "        print(k, nums_test,len(train_index))\n",
    "        train_df = train_dfs.loc[train_dfs['Index'].isin(train_index)]\n",
    "        k_recon_mse = bgk_pca(train_df,test_df)\n",
    "        results = model_comparison(train_df,test_df,models,para_grids, feature_list[0],gas_list,selected_index=selected_index)\n",
    "        temp_results  = []\n",
    "        for ele in results:\n",
    "            temp_results.append(ele+[k_recon_mse])\n",
    "        print(\"recons_mse: {:.4f}\".format(k_recon_mse))\n",
    "        big_results.append(temp_results)\n",
    "    #files_name = 'Res_pca_The_impact_of_different_training_sample_size_of_'+str((k+1)*interval)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "    #pd.DataFrame(temp_results,columns = columns).to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "file_name = ['BET_plus_Vt']\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\",'kpg_pca_mse']\n",
    "tpd = []\n",
    "for gas in gas_list:\n",
    "    \n",
    "    fraction = range(25,len(list(set(train_dfs[\"Index\"].values)))-50,interval)\n",
    "    #fraction = range(50,2125,interval)\n",
    "    for k in fraction: \n",
    "        df_list = []\n",
    "        for i in range(50):\n",
    "            for j in range(len(feature_list)):\n",
    "                files_name = 'Res_pca_The_impact_of_different_training_sample_size_of_'+str(k)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "                df_list.append(pd.read_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name))[cal_columns] )\n",
    "        pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',   str(k)+'-mean.csv'))\n",
    "        pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',str(k)+'-std.csv'))\n",
    "        tpd = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_r2</th>\n",
       "      <th>CV_mse</th>\n",
       "      <th>test_r2_separa_model</th>\n",
       "      <th>test_mse_separa_model</th>\n",
       "      <th>kpg_pca_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.792283</td>\n",
       "      <td>0.951128</td>\n",
       "      <td>0.576892</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944506</td>\n",
       "      <td>0.732007</td>\n",
       "      <td>0.938620</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>0.018231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CV_r2    CV_mse  test_r2_separa_model  test_mse_separa_model  \\\n",
       "0  0.939815  0.792283              0.951128               0.576892   \n",
       "1  0.944506  0.732007              0.938620               0.740196   \n",
       "\n",
       "   kpg_pca_mse  \n",
       "0     0.018231  \n",
       "1     0.018231  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpd[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-post treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./3_The_impact_of_different_training_sample_size\" #/Methane-25(test)-775(max training)-with-reconstruction-mse\n",
    "mean_df = pd.DataFrame()\n",
    "std_df = pd.DataFrame()\n",
    "for i in  range(25,len(list(set(train_dfs[\"Index\"].values)))-50,interval):\n",
    "    mean_temp = pd.read_csv(os.path.join(file_path,str(i)+'-mean.csv'))\n",
    "    std_temp = pd.read_csv(os.path.join(file_path,str(i)+'-std.csv'))\n",
    "    mean_df = pd.concat([mean_df,mean_temp],axis = 0)\n",
    "    std_df = pd.concat([std_df,std_temp],axis = 0)\n",
    "mean_df.to_csv(os.path.join(file_path,\"Total_mean.csv\"))\n",
    "std_df.to_csv(os.path.join(file_path,\"Total_std.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only calculating the reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n",
      "2145\n",
      "0\n",
      "0 50\n",
      "1\n",
      "1 100\n",
      "2\n",
      "2 150\n",
      "3\n",
      "3 200\n",
      "4\n",
      "4 250\n",
      "5\n",
      "5 300\n",
      "6\n",
      "6 350\n",
      "7\n",
      "7 400\n",
      "8\n",
      "8 450\n",
      "9\n",
      "9 500\n",
      "10\n",
      "10 550\n",
      "11\n",
      "11 600\n",
      "12\n",
      "12 650\n",
      "13\n",
      "13 700\n",
      "14\n",
      "14 750\n",
      "15\n",
      "15 800\n",
      "16\n",
      "16 850\n",
      "17\n",
      "17 900\n",
      "18\n",
      "18 950\n",
      "19\n",
      "19 1000\n",
      "20\n",
      "20 1050\n",
      "21\n",
      "21 1100\n",
      "22\n",
      "22 1150\n",
      "23\n",
      "23 1200\n",
      "24\n",
      "24 1250\n",
      "25\n",
      "25 1300\n",
      "26\n",
      "26 1350\n",
      "27\n",
      "27 1400\n",
      "28\n",
      "28 1450\n",
      "29\n",
      "29 1500\n",
      "30\n",
      "30 1550\n",
      "31\n",
      "31 1600\n",
      "32\n",
      "32 1650\n",
      "33\n",
      "33 1700\n",
      "34\n",
      "34 1750\n",
      "35\n",
      "35 1800\n",
      "36\n",
      "36 1850\n",
      "37\n",
      "37 1900\n",
      "38\n",
      "38 1950\n",
      "39\n",
      "39 2000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_3 = ['Vt',\"Vmic\",] \n",
    "combin_5 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_6 = [\"Vmic\",'Vmeso',]\n",
    "feature_list = [base_feature+combin_1+condition_feature]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param','kpg_pca_mse']\n",
    "#file_name = ['Total',\"Meso\",\"Micro\",'All','Vmic_meso']\n",
    "file_name = ['BET_plus_Vt']\n",
    "feature_set = [\"Vt\",]\n",
    "gas_list = ['CO2']\n",
    "\n",
    "for i in range(15):\n",
    "    recons_error = []\n",
    "    train_index = []\n",
    "    train_dfs,test_df = pred_dataset(gas_list,feature_set)#\n",
    "    nums_test = len(list(set(test_df[\"Index\"].values)))\n",
    "    \n",
    "    index = list(set(train_dfs['Index'].values))\n",
    "    fraction = range(100,len(list(set(train_dfs[\"Index\"].values))),50)\n",
    "    for k in range(len(fraction)):\n",
    "        print(k)\n",
    "        \n",
    "        #k = 50\n",
    "        selected_index = np.random.choice(index,50,replace=False)\n",
    "        \n",
    "        for ele in selected_index:\n",
    "            index.remove(ele)\n",
    "        train_index.extend(selected_index) \n",
    "        print(k, len(train_index))\n",
    "        train_df = temp_df.loc[temp_df['Index'].isin(train_index)]\n",
    "        k_recon_mse = bgk_pca(train_df,test_df)\n",
    "        recons_error.append(k_recon_mse)\n",
    "        files_name = 'Res_pca_The_impact_of_different_training_sample_size_of_'+str(50*k)+\"_\"+file_name[0]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(recons_error).to_csv(os.path.join('./3_The_impact_of_different_training_sample_size',files_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
