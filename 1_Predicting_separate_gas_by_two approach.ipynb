{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. predicting adsorption for each adsorption data point using Vt&BET only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'./src/')\n",
    "from model_sets import models,para_grids\n",
    "from preprocessing import pred_dataset\n",
    "from model_opt import model_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVR', SVR(max_iter=10000)),\n",
       " ('DT', DecisionTreeRegressor(random_state=42)),\n",
       " ('ADBR', AdaBoostRegressor(random_state=42)),\n",
       " ('GBR', GradientBoostingRegressor(random_state=42)),\n",
       " ('BG', BaggingRegressor(n_jobs=-1, random_state=42)),\n",
       " ('ETR', ExtraTreesRegressor(n_jobs=-1, random_state=42)),\n",
       " ('RF', RandomForestRegressor(n_jobs=-1, random_state=42)),\n",
       " ('LGBM', LGBMRegressor(random_state=42))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CO2, Algorithm GBR_total, Test_r2 0.9554, Test_error 0.4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/miniforge3/envs/torch_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CO2, Algorithm ETR_total, Test_r2 0.941, Test_error 0.6246\n",
      "Dataset CO2, Algorithm RF_total, Test_r2 0.9392, Test_error 0.6676\n",
      "Dataset CFCs, Algorithm GBR_total, Test_r2 0.9422, Test_error 0.981\n",
      "Dataset CFCs, Algorithm ETR_total, Test_r2 0.9167, Test_error 1.2766\n",
      "Dataset CFCs, Algorithm RF_total, Test_r2 0.9005, Test_error 1.6977\n",
      "Dataset Methane, Algorithm GBR_total, Test_r2 0.8891, Test_error 1.1028\n",
      "Dataset Methane, Algorithm ETR_total, Test_r2 0.9024, Test_error 0.9201\n",
      "Dataset Methane, Algorithm RF_total, Test_r2 0.8856, Test_error 1.0892\n",
      "Dataset E&E, Algorithm GBR_total, Test_r2 0.9268, Test_error 0.5848\n",
      "Dataset E&E, Algorithm ETR_total, Test_r2 0.8984, Test_error 0.7945\n",
      "Dataset E&E, Algorithm RF_total, Test_r2 0.8725, Test_error 1.0012\n",
      "Dataset CO2, Algorithm GBR_total, Test_r2 0.9439, Test_error 0.6166\n",
      "Dataset CO2, Algorithm ETR_total, Test_r2 0.9221, Test_error 0.8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/miniforge3/envs/torch_env/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CO2, Algorithm RF_total, Test_r2 0.9234, Test_error 0.8358\n",
      "Dataset CFCs, Algorithm GBR_total, Test_r2 0.9462, Test_error 0.9145\n",
      "Dataset CFCs, Algorithm ETR_total, Test_r2 0.9007, Test_error 1.4092\n",
      "Dataset CFCs, Algorithm RF_total, Test_r2 0.9061, Test_error 1.5245\n",
      "Dataset Methane, Algorithm GBR_total, Test_r2 0.909, Test_error 0.8502\n",
      "Dataset Methane, Algorithm ETR_total, Test_r2 0.8941, Test_error 0.9612\n",
      "Dataset Methane, Algorithm RF_total, Test_r2 0.8891, Test_error 1.0094\n",
      "Dataset E&E, Algorithm GBR_total, Test_r2 0.9396, Test_error 0.4469\n",
      "Dataset E&E, Algorithm ETR_total, Test_r2 0.8826, Test_error 0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:22<39:23, 262.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset E&E, Algorithm RF_total, Test_r2 0.8762, Test_error 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:44<42:40, 284.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     train_df,test_df \u001b[39m=\u001b[39m pred_dataset([\u001b[39m'\u001b[39m\u001b[39mCO2-04-19-2022.xlsx\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMethane-02-02-2022.xlsx\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mEthane&Ethylene-02-02-2022.xlsx\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCFCs-04-28-2022.xlsx\u001b[39m\u001b[39m'\u001b[39m],feature_set,random_state \u001b[39m=\u001b[39m i)\n\u001b[1;32m     21\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feature_list)):\n\u001b[0;32m---> 22\u001b[0m         result \u001b[39m=\u001b[39m model_comparison(train_df,test_df,[models[\u001b[39m3\u001b[39;49m],models[\u001b[39m5\u001b[39;49m],models[\u001b[39m6\u001b[39;49m]],para_grids, feature_list[j],gas_list)\n\u001b[1;32m     23\u001b[0m         result\u001b[39m.\u001b[39mappend(result)\n\u001b[1;32m     24\u001b[0m files_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGBR_ETR_LGBM_Full_Four_gases_with_pred_Vmic_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfile_name[j]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_result_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/Kai_Zhang/MachineLearning/Unified gas Adsorption/./src/model_opt.py:76\u001b[0m, in \u001b[0;36mmodel_comparison\u001b[0;34m(train_df, test_df, model_list, para_grids, feature_list, gas_list, output, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m train_x, train_y, groups \u001b[39m=\u001b[39m shuffle(train_x, train_y, groups, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m model_list:\n\u001b[0;32m---> 76\u001b[0m     result, best_param \u001b[39m=\u001b[39m model_CV(train_x,train_y\u001b[39m.\u001b[39;49msqueeze(),groups,model,para_grids[model_name])\n\u001b[1;32m     77\u001b[0m     model_refit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_param)\n\u001b[1;32m     78\u001b[0m     model_refit\u001b[39m.\u001b[39mfit(train_x,train_y\u001b[39m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/Downloads/Kai_Zhang/MachineLearning/Unified gas Adsorption/./src/model_opt.py:20\u001b[0m, in \u001b[0;36mmodel_CV\u001b[0;34m(train_x, train_y, groups, model, para_grid, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m out_cv \u001b[39m=\u001b[39m GroupKFold(n_splits \u001b[39m=\u001b[39m n_splits)\n\u001b[1;32m     18\u001b[0m result \u001b[39m=\u001b[39m GridSearchCV(model,para_grid,cv\u001b[39m=\u001b[39m out_cv\u001b[39m.\u001b[39mget_n_splits(groups \u001b[39m=\u001b[39mgroups),\n\u001b[1;32m     19\u001b[0m scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m, return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m result\u001b[39m.\u001b[39;49mfit(train_x,train_y)\n\u001b[1;32m     22\u001b[0m model_refit \u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresult\u001b[39m.\u001b[39mbest_params_)\n\u001b[1;32m     23\u001b[0m train_cv \u001b[39m=\u001b[39m cross_validate(model_refit,train_x,train_y,groups \u001b[39m=\u001b[39m groups,cv \u001b[39m=\u001b[39mout_cv,scoring \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "pysical_prop = np.array(['Vt','Vmeso','Vmic'])\n",
    "combin_1,combin_2,combin3 = [pysical_prop[0]],[pysical_prop[1]],[pysical_prop[2]]\n",
    "combin_4,combin_5,combin_6 = pysical_prop[[0,1]],pysical_prop[[0,2]],pysical_prop[[1,2]]\n",
    "combin_7 = pysical_prop\n",
    "\n",
    "feature_list = [base_feature+combin_1+condition_feature,base_feature+condition_feature]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "#file_name = ['Total',\"Meso\",\"Micro\",'All','Vmic_meso']\n",
    "file_name = ['BET_only','BET_plut_Vt']\n",
    "feature_set = [\"BET\",\"Vt\",]\n",
    "gas_list = ['CO2','CFCs','Methane','E&E']\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    train_df,test_df = pred_dataset(['CO2-04-19-2022.xlsx','Methane-02-02-2022.xlsx','Ethane&Ethylene-02-02-2022.xlsx','CFCs-04-28-2022.xlsx'],feature_set,random_state = i)\n",
    "    for j in range(len(feature_list)):\n",
    "        result = model_comparison(train_df,test_df,[models[3],models[5],models[7]],para_grids, feature_list[j],gas_list)\n",
    "        result.append(result)\n",
    "files_name = 'GBR_ETR_LGBM_Full_Four_gases_with_pred_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "pd.DataFrame(results,columns = columns).to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach',files_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatments\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = ['BET_only','BET_plut_Vt']\n",
    "df_list = []\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for j in range(1):\n",
    "    for i in range(15):\n",
    "    \n",
    "        files_name = 'BG_ETR_Full_Four_gases_with_pred_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        df_list.append(pd.read_csv(os.path.join('./1_Predicting_separate_gas_by_two approach',files_name))[cal_columns] )\n",
    "        pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach','mean.csv'))\n",
    "        pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach','std.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_Predicting adsorption for each data point using the combination Vt, BET, Vmeso, and Vmic\n",
    "the dataset for each separate gas will be smaller than previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_5 = ['Vt',\"Vmic\",]\n",
    "combin_6 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_7 = [\"Vmic\",'Vmeso',]\n",
    "\n",
    "feature_list = [base_feature+condition_feature,base_feature+combin_1+condition_feature, \\\n",
    "    base_feature+combin_3+condition_feature, base_feature+combin_2+condition_feature,\\\n",
    "    base_feature+combin_4+condition_feature, base_feature+combin_5+condition_feature,\\\n",
    "    base_feature+combin_6+condition_feature, base_feature+combin_7+condition_feature, ]\n",
    "\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "\n",
    "\n",
    "feature_set = [\"BET\",\"Vt\",\"Vmeso\",\"Vmic\"]\n",
    "gas_list = ['CO2','CFCs','Methane','E&E']\n",
    "file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "\n",
    "\n",
    "for i in range(10,15):\n",
    "    train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'],feature_set= feature_set)\n",
    "    for j in range(len(feature_list)):\n",
    "        results = model_comparison(models,para_grids, feature_list[j],gas_list)\n",
    "        files_name = 'Four_gases_with_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(results,columns = columns).to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',files_name))  \n",
    "        #pd.DataFrame(results,columns = ['Gas','Algo','Train_erro','Test_error']).to_csv(os.path.join('./',files_name))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for j in range(len(file_name)):\n",
    "    df_list = []\n",
    "    for i in range(11):\n",
    "    \n",
    "        files_name = 'Four_gases_with_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        df_list.append(pd.read_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',files_name))[cal_columns] )\n",
    "        pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',file_name[j]+'_mean_new.csv'))\n",
    "        pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',file_name[j]+'_std_new.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the fitted parameters of adsorption isotherms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only BET and Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pred_dataset(file_names, feature_set = feature_set):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-fitting-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        train_x,test_x = train_test_split(temp_data,test_size = 0.2)\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,model,para_grid):\n",
    "\n",
    "    \n",
    "    result = GridSearchCV(model,para_grid,cv= 5,\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,cv =5,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "        if gas =='total':\n",
    "\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y,random_state=42)\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                \n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                for gases in gas_list[1:]:\n",
    "                    test_df_com = test_df[test_df['Label']==gases]\n",
    "                    test_xs = test_df_com[input_feature]\n",
    "                    test_ys = test_df_com[output].values\n",
    "                    test_r2,test_mse = model_eval(model_refit,test_xs,test_ys.squeeze()) \n",
    "                    result_total.append([gases,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "           \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print(print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    ")\n",
    "                \n",
    "    return result_total"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
