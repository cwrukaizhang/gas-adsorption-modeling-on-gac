{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. predicting adsorption for each adsorption data point using Vt&BET only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "def pred_dataset(file_names, feature_set,random_state=42 ):\n",
    "    source_path = './CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        #temp_data = temp_data[temp_data['Pressure']>0.01]\n",
    "        index = list(set(temp_data['Index'].values))\n",
    "        print(len(index))\n",
    "        test_index = shuffle(index,random_state = random_state)[:int(0.2*len(index))]\n",
    "        train_x = temp_data.loc[~temp_data['Index'].isin( test_index)]\n",
    "        test_x = temp_data.loc[temp_data['Index'].isin(test_index)]\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,\\\n",
    "    BaggingRegressor,ExtraTreesRegressor,RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor  \n",
    "from sklearn.svm import SVR\n",
    "  \n",
    "n_estimators = [50,100,120,150,180,200]\n",
    "\n",
    "# define different models#,\n",
    "models = [\n",
    "    #('SVR',SVR(max_iter=100000)),\n",
    "    # ('DT',DecisionTreeRegressor(random_state=42)),\\\n",
    "    # ('ADBR',AdaBoostRegressor(random_state=42)), \n",
    "    (\"GBR\",GradientBoostingRegressor(random_state=42)),\\\n",
    "    #('BG',BaggingRegressor(random_state=42,n_jobs=-1)),\n",
    "    ('ETR',ExtraTreesRegressor(random_state=42,n_jobs=-1)),\\\n",
    "    #('RF',RandomForestRegressor(n_jobs=-1,random_state=42)),\n",
    "    ('LGBM',LGBMRegressor(n_jobs = -1,random_state = 42)),\\\n",
    "    #('BGLGBM',BaggingRegressor(LGBMRegressor(n_estimators = 200, n_jobs = -1,random_state = 42), random_state=42,n_jobs=-1)),\\\n",
    "    #('BGETR',BaggingRegressor(ExtraTreesRegressor(n_estimators = 180,random_state=42,n_jobs=6),random_state=42,n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "# set search parameters grid for different models\n",
    "para_grids = { \n",
    "    'SVR':{'kernel':['linear','poly','rbf','sigmoid','precomputed']},\\\n",
    "    'DT':{'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson']},\\\n",
    "    'ADBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2],'loss':['linear','square','exponential']},\\\n",
    "    'GBR':{'n_estimators':n_estimators,'learning_rate':[0.1,0.5,1,2]},\\\n",
    "    'BG':{'n_estimators':[10,50,100]},\\\n",
    "    'ETR':{'n_estimators':n_estimators},\\\n",
    "    'RF':{'n_estimators':n_estimators},\\\n",
    "    'LGBM':{'num_leaves':[10,20,30,50],'learning_rate': [0.05,0.1,0.5,1],'n_estimators':n_estimators},\\\n",
    "    'BGLGBM':{'n_estimators':[10,30,50]},\\\n",
    "    'BGETR':{'n_estimators':[10]}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,groups,model,para_grid):\n",
    "\n",
    "    out_cv = GroupKFold(n_splits = 5)\n",
    "    result = GridSearchCV(model,para_grid,cv= out_cv.get_n_splits(groups =groups),\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,groups = groups,cv =out_cv,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "    for gas in gas_list:\n",
    "        if gas =='total':\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index'].values\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            print(groups)\n",
    "            for model_name, model in model_list:\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                for gases in gas_list[1:]:\n",
    "                    test_df_com = test_df[test_df['Label']==gases]\n",
    "                    test_xs = test_df_com[input_feature]\n",
    "                    test_ys = test_df_com[output].values\n",
    "                    test_r2,test_mse = model_eval(model_refit,test_xs,test_ys.squeeze()) \n",
    "                    result_total.append([gases,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))    \n",
    "        else:\n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            groups = train_df_com['Index']\n",
    "            train_x, train_y, groups = shuffle(train_x, train_y, groups, random_state=42)\n",
    "            for model_name, model in model_list:\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),groups,model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))     \n",
    "    return result_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value must be either numerical or a string containing a wildcard",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m gas_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCO2\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mCFCs\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mMethane\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mE&E\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     train_df,test_df \u001b[39m=\u001b[39m pred_dataset([\u001b[39m'\u001b[39;49m\u001b[39mCO2\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mMethane\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mEthane&Ethylene\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mCFCs\u001b[39;49m\u001b[39m'\u001b[39;49m],feature_set,random_state \u001b[39m=\u001b[39;49m i)\n\u001b[1;32m     19\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feature_list)):\n\u001b[1;32m     20\u001b[0m         results \u001b[39m=\u001b[39m model_comparison(models,para_grids, feature_list[j],gas_list)\n",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mpred_dataset\u001b[0;34m(file_names, feature_set, random_state)\u001b[0m\n\u001b[1;32m      8\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m file_names:\n\u001b[0;32m---> 10\u001b[0m     temp_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(source_path,file_name\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m-02-02-2022.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m),skiprows\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m )\n\u001b[1;32m     11\u001b[0m     temp_data \u001b[39m=\u001b[39m temp_data\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,how \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39many\u001b[39m\u001b[39m'\u001b[39m,subset \u001b[39m=\u001b[39m feature_set)\n\u001b[1;32m     12\u001b[0m     \u001b[39m#temp_data = temp_data[temp_data['Pressure']>0.01]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/pandas/io/excel/_base.py:486\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mparse(\n\u001b[1;32m    487\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[1;32m    488\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m    489\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    490\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    491\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m    492\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    493\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m    494\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[1;32m    495\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[1;32m    496\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m    497\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m    498\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m    499\u001b[0m         keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m    500\u001b[0m         na_filter\u001b[39m=\u001b[39;49mna_filter,\n\u001b[1;32m    501\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    502\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    503\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[1;32m    504\u001b[0m         date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m    505\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m    506\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m    507\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[1;32m    508\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[1;32m    509\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m    510\u001b[0m     )\n\u001b[1;32m    511\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/pandas/io/excel/_base.py:1551\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[1;32m   1519\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1520\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1538\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[1;32m   1539\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[1;32m   1540\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1542\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[1;32m   1550\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1551\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mparse(\n\u001b[1;32m   1552\u001b[0m         sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[1;32m   1553\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1554\u001b[0m         names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m   1555\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1556\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1557\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1558\u001b[0m         true_values\u001b[39m=\u001b[39;49mtrue_values,\n\u001b[1;32m   1559\u001b[0m         false_values\u001b[39m=\u001b[39;49mfalse_values,\n\u001b[1;32m   1560\u001b[0m         skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1561\u001b[0m         nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[1;32m   1562\u001b[0m         na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1563\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1564\u001b[0m         date_parser\u001b[39m=\u001b[39;49mdate_parser,\n\u001b[1;32m   1565\u001b[0m         date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   1566\u001b[0m         thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1567\u001b[0m         comment\u001b[39m=\u001b[39;49mcomment,\n\u001b[1;32m   1568\u001b[0m         skipfooter\u001b[39m=\u001b[39;49mskipfooter,\n\u001b[1;32m   1569\u001b[0m         dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[1;32m   1570\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m   1571\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/pandas/io/excel/_base.py:751\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m    748\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[1;32m    750\u001b[0m file_rows_needed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[0;32m--> 751\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_sheet_data(sheet, file_rows_needed)\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(sheet, \u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    753\u001b[0m     \u001b[39m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     sheet\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py:602\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[0;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[1;32m    600\u001b[0m data: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[Scalar]] \u001b[39m=\u001b[39m []\n\u001b[1;32m    601\u001b[0m last_row_with_data \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 602\u001b[0m \u001b[39mfor\u001b[39;00m row_number, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sheet\u001b[39m.\u001b[39mrows):\n\u001b[1;32m    603\u001b[0m     converted_row \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_cell(cell) \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m row]\n\u001b[1;32m    604\u001b[0m     \u001b[39mwhile\u001b[39;00m converted_row \u001b[39mand\u001b[39;00m converted_row[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    605\u001b[0m         \u001b[39m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[0;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[1;32m     75\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_source()\n\u001b[1;32m     76\u001b[0m parser \u001b[39m=\u001b[39m WorkSheetParser(src, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_strings,\n\u001b[1;32m     77\u001b[0m                          data_only\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mdata_only, epoch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mepoch,\n\u001b[1;32m     78\u001b[0m                          date_formats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39m_date_formats)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m parser\u001b[39m.\u001b[39mparse():\n\u001b[1;32m     80\u001b[0m     \u001b[39mif\u001b[39;00m max_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m idx \u001b[39m>\u001b[39m max_row:\n\u001b[1;32m     81\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/worksheet/_reader.py:163\u001b[0m, in \u001b[0;36mparse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py:87\u001b[0m, in \u001b[0;36mSerialisable.from_tree\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(desc\u001b[39m.\u001b[39mexpected_type, \u001b[39m\"\u001b[39m\u001b[39mfrom_tree\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m         \u001b[39m#complex type\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         obj \u001b[39m=\u001b[39m desc\u001b[39m.\u001b[39;49mexpected_type\u001b[39m.\u001b[39;49mfrom_tree(el)\n\u001b[1;32m     88\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         \u001b[39m#primitive\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         obj \u001b[39m=\u001b[39m el\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py:87\u001b[0m, in \u001b[0;36mSerialisable.from_tree\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(desc\u001b[39m.\u001b[39mexpected_type, \u001b[39m\"\u001b[39m\u001b[39mfrom_tree\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m         \u001b[39m#complex type\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         obj \u001b[39m=\u001b[39m desc\u001b[39m.\u001b[39;49mexpected_type\u001b[39m.\u001b[39;49mfrom_tree(el)\n\u001b[1;32m     88\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         \u001b[39m#primitive\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         obj \u001b[39m=\u001b[39m el\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py:87\u001b[0m, in \u001b[0;36mSerialisable.from_tree\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(desc\u001b[39m.\u001b[39mexpected_type, \u001b[39m\"\u001b[39m\u001b[39mfrom_tree\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m         \u001b[39m#complex type\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m         obj \u001b[39m=\u001b[39m desc\u001b[39m.\u001b[39;49mexpected_type\u001b[39m.\u001b[39;49mfrom_tree(el)\n\u001b[1;32m     88\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m         \u001b[39m#primitive\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         obj \u001b[39m=\u001b[39m el\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/descriptors/serialisable.py:103\u001b[0m, in \u001b[0;36mSerialisable.from_tree\u001b[0;34m(cls, node)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         attrib[tag] \u001b[39m=\u001b[39m obj\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mattrib)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/worksheet/filters.py:184\u001b[0m, in \u001b[0;36mCustomFilter.__init__\u001b[0;34m(self, operator, val)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    180\u001b[0m              operator\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m              val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m             ):\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moperator \u001b[39m=\u001b[39m operator\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32m~/miniforge3/envs/torch_env/lib/python3.9/site-packages/openpyxl/worksheet/filters.py:165\u001b[0m, in \u001b[0;36mCustomFilterValueDescriptor.__set__\u001b[0;34m(self, instance, value)\u001b[0m\n\u001b[1;32m    163\u001b[0m m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpattern\u001b[39m.\u001b[39mmatch(value)\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValue must be either numerical or a string containing a wildcard\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m value:\n\u001b[1;32m    167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_type \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Value must be either numerical or a string containing a wildcard"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_3 = ['Vt',\"Vmic\",]\n",
    "combin_5 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_6 = [\"Vmic\",'Vmeso',]\n",
    "feature_list = [base_feature+combin_5+condition_feature]\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "#file_name = ['Total',\"Meso\",\"Micro\",'All','Vmic_meso']\n",
    "file_name = ['BET_only','BET_plut_Vt']\n",
    "feature_set = [\"BET\",\"Vt\",'Vmic','Vmeso']\n",
    "gas_list = ['total','CO2','CFCs','Methane','E&E']\n",
    "for i in range(50):\n",
    "    train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'],feature_set,random_state = i)\n",
    "    for j in range(len(feature_list)):\n",
    "        results = model_comparison(models,para_grids, feature_list[j],gas_list)\n",
    "        files_name = 'LGBM_ETR_Full_Four_gases_with_pred_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(results,columns = columns).to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach',files_name))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatments\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = ['BET_only','BET_plut_Vt']\n",
    "df_list = []\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for j in range(1):\n",
    "    for i in range(50):\n",
    "    \n",
    "        files_name = 'LGBM_ETR_Full_Four_gases_with_pred_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        df_list.append(pd.read_csv(os.path.join('./1_Predicting_separate_gas_by_two approach',files_name))[cal_columns] )\n",
    "        pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach','mean.csv'))\n",
    "        pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./1_Predicting_separate_gas_by_two approach','std.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_Predicting adsorption for each data point using the combination Vt, BET, Vmeso, and Vmic\n",
    "the dataset for each separate gas will be smaller than previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_feature = ['V','S','L','BET',]\n",
    "condition_feature = ['Temp(K)','Pressure']\n",
    "combin_1 = ['Vt']\n",
    "combin_2 = [\"Vmeso\"]\n",
    "combin_3 = ['Vmic']\n",
    "combin_4 = ['Vt',\"Vmeso\",]\n",
    "combin_5 = ['Vt',\"Vmic\",]\n",
    "combin_6 = ['Vt',\"Vmic\",'Vmeso',]\n",
    "combin_7 = [\"Vmic\",'Vmeso',]\n",
    "\n",
    "feature_list = [base_feature+condition_feature,base_feature+combin_1+condition_feature, \\\n",
    "    base_feature+combin_3+condition_feature, base_feature+combin_2+condition_feature,\\\n",
    "    base_feature+combin_4+condition_feature, base_feature+combin_5+condition_feature,\\\n",
    "    base_feature+combin_6+condition_feature, base_feature+combin_7+condition_feature, ]\n",
    "\n",
    "columns = ['Gas','Model_name','CV_r2','CV_mse','test_r2_total_model','test_mse_by_total_model','test_r2_separa_model','test_mse_separa_model','best_param']\n",
    "\n",
    "\n",
    "feature_set = [\"BET\",\"Vt\",\"Vmeso\",\"Vmic\"]\n",
    "gas_list = ['CO2','CFCs','Methane','E&E']\n",
    "file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "\n",
    "\n",
    "for i in range(10,15):\n",
    "    train_df,test_df = pred_dataset(['CO2','Methane','Ethane&Ethylene','CFCs'],feature_set= feature_set)\n",
    "    for j in range(len(feature_list)):\n",
    "        results = model_comparison(models,para_grids, feature_list[j],gas_list)\n",
    "        files_name = 'Four_gases_with_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        pd.DataFrame(results,columns = columns).to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',files_name))  \n",
    "        #pd.DataFrame(results,columns = ['Gas','Algo','Train_erro','Test_error']).to_csv(os.path.join('./',files_name))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post result treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = ['BET_only','BET_plut_Vt',\"BET_Vmic\",\"BET_Vmeso\",'BET_Vt_Vmeso','BET_Vt_Vmic',\"BET_Vt_Vmic_meso\",\"BET_Vmic_meso\"]\n",
    "\n",
    "cal_columns= [\"CV_r2\",\"CV_mse\",\"test_r2_separa_model\",\"test_mse_separa_model\"]\n",
    "for j in range(len(file_name)):\n",
    "    df_list = []\n",
    "    for i in range(11):\n",
    "    \n",
    "        files_name = 'Four_gases_with_Vmic_'+file_name[j]+'_result_'+str(i)+'.csv'\n",
    "        df_list.append(pd.read_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',files_name))[cal_columns] )\n",
    "        pd.concat(df_list).groupby(level=0).mean().to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',file_name[j]+'_mean_new.csv'))\n",
    "        pd.concat(df_list).groupby(level=0).std().to_csv(os.path.join('./2_Predicting_separate_gas_BET_Vt_Vmeso_Vmic',file_name[j]+'_std_new.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the fitted parameters of adsorption isotherms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only BET and Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pred_dataset(file_names, feature_set = feature_set):\n",
    "    source_path = 'C:/Kai_Zhang/MachineLearning/Unified gas Adsorption/CO2_adsorption/new_data'\n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "    for file_name in file_names:\n",
    "        temp_data = pd.read_excel(os.path.join(source_path,file_name+'-fitting-02-02-2022.xlsx'),skiprows= 1 )\n",
    "        temp_data = temp_data.dropna(axis=0,how = 'any',subset = feature_set)\n",
    "        train_x,test_x = train_test_split(temp_data,test_size = 0.2)\n",
    "        train_df = pd.concat([train_df,train_x],axis=0)\n",
    "        test_df = pd.concat([test_df,test_x],axis =0)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,GroupKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from  sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def model_CV(train_x,train_y,model,para_grid):\n",
    "\n",
    "    \n",
    "    result = GridSearchCV(model,para_grid,cv= 5,\n",
    "    scoring='neg_mean_squared_error', return_train_score=True,n_jobs=-1)\n",
    "    result.fit(train_x,train_y)\n",
    "    \n",
    "    model_refit =model.set_params(**result.best_params_)\n",
    "    train_cv = cross_validate(model_refit,train_x,train_y,cv =5,scoring = ('r2', 'neg_mean_squared_error'))\n",
    "    train_mse_cv = -train_cv['test_neg_mean_squared_error'].mean()\n",
    "    train_r2_cv = train_cv['test_r2'].mean()\n",
    "    \n",
    "    return [train_r2_cv,train_mse_cv],result.best_params_\n",
    "\n",
    "# model evaluation\n",
    "def model_eval(model,test_x,test_y):\n",
    "      \n",
    "    test_pre = model.predict(test_x)\n",
    "    test_r2 = r2_score(test_pre,test_y)\n",
    "    test_mse = mean_squared_error(test_y,test_pre)\n",
    "    return test_r2,test_mse\n",
    "\n",
    "# comparing different models\n",
    "def model_comparison(model_list,para_grids,feature_list,gas_list):\n",
    "    gas_list = gas_list \n",
    "    input_feature = feature_list\n",
    "    output = ['Adsorp(mmol/g)']\n",
    "    result_total = []\n",
    "\n",
    "    for gas in gas_list:\n",
    "        \n",
    "        if gas =='total':\n",
    "\n",
    "            train_df_com = train_df\n",
    "            test_df_com = test_df\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y,random_state=42)\n",
    "            \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                \n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2_total,test_mse_total = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                for gases in gas_list[1:]:\n",
    "                    test_df_com = test_df[test_df['Label']==gases]\n",
    "                    test_xs = test_df_com[input_feature]\n",
    "                    test_ys = test_df_com[output].values\n",
    "                    test_r2,test_mse = model_eval(model_refit,test_xs,test_ys.squeeze()) \n",
    "                    result_total.append([gases,model_name+'_total',result[0],result[1],test_r2_total,test_mse_total,test_r2,test_mse,best_param])\n",
    "\n",
    "                    print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train_df_com = train_df[train_df['Label']==gas]\n",
    "            test_df_com = test_df[test_df['Label']==gas]\n",
    "            train_x = train_df_com[input_feature]\n",
    "            test_x = test_df_com[input_feature]\n",
    "            train_y = train_df_com[output].values\n",
    "            test_y = test_df_com[output].values\n",
    "            \n",
    "            train_x, train_y = shuffle(train_x, train_y, random_state=42)\n",
    "           \n",
    "            for model_name, model in model_list:\n",
    "\n",
    "                result, best_param = model_CV(train_x,train_y.squeeze(),model,para_grids[model_name])\n",
    "                model_refit = model.set_params(**best_param)\n",
    "                model_refit.fit(train_x,train_y.squeeze())\n",
    "                test_r2,test_mse = model_eval(model_refit,test_x,test_y.squeeze()) \n",
    "                result_total.append([gas,model_name+'_separate',result[0],result[1],-1,-1, test_r2,test_mse,best_param])\n",
    "                \n",
    "                print(print('Dataset {}, Algorithm {}, Test_r2 {}, Test_error {}'.format(gas,model_name+'_total',test_r2,test_mse))\n",
    ")\n",
    "                \n",
    "    return result_total"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cded950f7e8b102373b7ffb2d1ae075c531242f5ad58e5bbcdb99f4873d2799c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch_optuna': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
